{
  "best_metric": 0.22841547429561615,
  "best_model_checkpoint": "/home/bo/Dropbox/Projects/kg-llm-uq/llamas/models/checkpoint-5200",
  "epoch": 0.6996182371638553,
  "eval_steps": 200,
  "global_step": 5200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.2626923322677612,
      "learning_rate": 1.4999999999999999e-05,
      "loss": 3.5974,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.107495903968811,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 3.5532,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2379704713821411,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 3.3932,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.4463337659835815,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 3.2912,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3645246028900146,
      "learning_rate": 7.5e-05,
      "loss": 2.9576,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.372413158416748,
      "learning_rate": 8.999999999999999e-05,
      "loss": 2.586,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.739326000213623,
      "learning_rate": 0.00010499999999999999,
      "loss": 2.2116,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0133001804351807,
      "learning_rate": 0.00011999999999999999,
      "loss": 1.6297,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.269138216972351,
      "learning_rate": 0.000135,
      "loss": 1.1155,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7028073668479919,
      "learning_rate": 0.00015,
      "loss": 0.8901,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.493519127368927,
      "learning_rate": 0.000165,
      "loss": 0.7866,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4053221642971039,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.7483,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.45884114503860474,
      "learning_rate": 0.000195,
      "loss": 0.6903,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3343065083026886,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.6494,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3396775722503662,
      "learning_rate": 0.000225,
      "loss": 0.6104,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7700481414794922,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.5647,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4402700662612915,
      "learning_rate": 0.00025499999999999996,
      "loss": 0.5309,
      "step": 85
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.29860883951187134,
      "learning_rate": 0.00027,
      "loss": 0.4918,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2702193260192871,
      "learning_rate": 0.000285,
      "loss": 0.4564,
      "step": 95
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.23448915779590607,
      "learning_rate": 0.0003,
      "loss": 0.4685,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.24277015030384064,
      "learning_rate": 0.000299898401517204,
      "loss": 0.467,
      "step": 105
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25784987211227417,
      "learning_rate": 0.00029979680303440803,
      "loss": 0.4542,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.23393717408180237,
      "learning_rate": 0.00029969520455161197,
      "loss": 0.4499,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.28803443908691406,
      "learning_rate": 0.000299593606068816,
      "loss": 0.4286,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25995564460754395,
      "learning_rate": 0.00029949200758602,
      "loss": 0.4438,
      "step": 125
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.26047396659851074,
      "learning_rate": 0.000299390409103224,
      "loss": 0.4395,
      "step": 130
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24830776453018188,
      "learning_rate": 0.0002992888106204281,
      "loss": 0.4197,
      "step": 135
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.27706998586654663,
      "learning_rate": 0.000299187212137632,
      "loss": 0.4205,
      "step": 140
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25209641456604004,
      "learning_rate": 0.0002990856136548361,
      "loss": 0.4133,
      "step": 145
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.23784491419792175,
      "learning_rate": 0.0002989840151720401,
      "loss": 0.4184,
      "step": 150
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3255922794342041,
      "learning_rate": 0.0002988824166892441,
      "loss": 0.4248,
      "step": 155
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2626357674598694,
      "learning_rate": 0.0002987808182064481,
      "loss": 0.4125,
      "step": 160
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3296777904033661,
      "learning_rate": 0.0002986792197236521,
      "loss": 0.417,
      "step": 165
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.28870394825935364,
      "learning_rate": 0.0002985776212408561,
      "loss": 0.4174,
      "step": 170
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.26141318678855896,
      "learning_rate": 0.00029847602275806013,
      "loss": 0.3941,
      "step": 175
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.28623688220977783,
      "learning_rate": 0.00029837442427526413,
      "loss": 0.4053,
      "step": 180
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2560170888900757,
      "learning_rate": 0.00029827282579246813,
      "loss": 0.3895,
      "step": 185
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.234304279088974,
      "learning_rate": 0.00029817122730967213,
      "loss": 0.4022,
      "step": 190
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2814343571662903,
      "learning_rate": 0.00029806962882687613,
      "loss": 0.3918,
      "step": 195
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24950015544891357,
      "learning_rate": 0.0002979680303440802,
      "loss": 0.3954,
      "step": 200
    },
    {
      "epoch": 0.03,
      "eval_loss": 0.38420623540878296,
      "eval_runtime": 12.3149,
      "eval_samples_per_second": 8.12,
      "eval_steps_per_second": 1.056,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2803386151790619,
      "learning_rate": 0.0002978664318612842,
      "loss": 0.3765,
      "step": 205
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2545836865901947,
      "learning_rate": 0.0002977648333784882,
      "loss": 0.3765,
      "step": 210
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2669827938079834,
      "learning_rate": 0.0002976632348956922,
      "loss": 0.3933,
      "step": 215
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2532350718975067,
      "learning_rate": 0.0002975616364128962,
      "loss": 0.3866,
      "step": 220
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.23852205276489258,
      "learning_rate": 0.00029746003793010024,
      "loss": 0.3821,
      "step": 225
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2742677927017212,
      "learning_rate": 0.00029735843944730424,
      "loss": 0.386,
      "step": 230
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2712225019931793,
      "learning_rate": 0.00029725684096450824,
      "loss": 0.3788,
      "step": 235
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.30954912304878235,
      "learning_rate": 0.00029715524248171224,
      "loss": 0.3822,
      "step": 240
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.27805373072624207,
      "learning_rate": 0.00029705364399891624,
      "loss": 0.362,
      "step": 245
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.30852705240249634,
      "learning_rate": 0.00029695204551612024,
      "loss": 0.3689,
      "step": 250
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2927408516407013,
      "learning_rate": 0.0002968504470333243,
      "loss": 0.3733,
      "step": 255
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2632081210613251,
      "learning_rate": 0.0002967488485505283,
      "loss": 0.3754,
      "step": 260
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.27814340591430664,
      "learning_rate": 0.0002966472500677323,
      "loss": 0.365,
      "step": 265
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.28365612030029297,
      "learning_rate": 0.0002965456515849363,
      "loss": 0.3792,
      "step": 270
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2729274034500122,
      "learning_rate": 0.0002964440531021403,
      "loss": 0.3637,
      "step": 275
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.32091692090034485,
      "learning_rate": 0.00029634245461934434,
      "loss": 0.3635,
      "step": 280
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.26133450865745544,
      "learning_rate": 0.00029624085613654834,
      "loss": 0.3523,
      "step": 285
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.24839267134666443,
      "learning_rate": 0.00029613925765375234,
      "loss": 0.3564,
      "step": 290
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2871153950691223,
      "learning_rate": 0.00029603765917095634,
      "loss": 0.3594,
      "step": 295
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.30234313011169434,
      "learning_rate": 0.00029593606068816034,
      "loss": 0.3657,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2983761131763458,
      "learning_rate": 0.0002958344622053644,
      "loss": 0.37,
      "step": 305
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2795599102973938,
      "learning_rate": 0.0002957328637225684,
      "loss": 0.35,
      "step": 310
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2880208492279053,
      "learning_rate": 0.0002956312652397724,
      "loss": 0.3577,
      "step": 315
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.2670629918575287,
      "learning_rate": 0.0002955296667569764,
      "loss": 0.357,
      "step": 320
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.25444599986076355,
      "learning_rate": 0.0002954280682741804,
      "loss": 0.3582,
      "step": 325
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.27631184458732605,
      "learning_rate": 0.00029532646979138445,
      "loss": 0.3604,
      "step": 330
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.30944526195526123,
      "learning_rate": 0.00029522487130858845,
      "loss": 0.3567,
      "step": 335
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.28717267513275146,
      "learning_rate": 0.00029512327282579245,
      "loss": 0.3659,
      "step": 340
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.30423086881637573,
      "learning_rate": 0.00029502167434299645,
      "loss": 0.3448,
      "step": 345
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.36928728222846985,
      "learning_rate": 0.00029492007586020045,
      "loss": 0.3493,
      "step": 350
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.28363946080207825,
      "learning_rate": 0.00029481847737740445,
      "loss": 0.3415,
      "step": 355
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.28163614869117737,
      "learning_rate": 0.0002947168788946085,
      "loss": 0.3498,
      "step": 360
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2833423614501953,
      "learning_rate": 0.0002946152804118125,
      "loss": 0.3462,
      "step": 365
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.30947446823120117,
      "learning_rate": 0.0002945136819290165,
      "loss": 0.3515,
      "step": 370
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2858450412750244,
      "learning_rate": 0.0002944120834462205,
      "loss": 0.3487,
      "step": 375
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2966090440750122,
      "learning_rate": 0.0002943104849634245,
      "loss": 0.3367,
      "step": 380
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.30528903007507324,
      "learning_rate": 0.00029420888648062855,
      "loss": 0.333,
      "step": 385
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2834186851978302,
      "learning_rate": 0.00029410728799783255,
      "loss": 0.3432,
      "step": 390
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2934437692165375,
      "learning_rate": 0.00029400568951503655,
      "loss": 0.3392,
      "step": 395
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2735375761985779,
      "learning_rate": 0.00029390409103224055,
      "loss": 0.3281,
      "step": 400
    },
    {
      "epoch": 0.05,
      "eval_loss": 0.32198676466941833,
      "eval_runtime": 12.3148,
      "eval_samples_per_second": 8.12,
      "eval_steps_per_second": 1.056,
      "step": 400
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2680514454841614,
      "learning_rate": 0.00029380249254944455,
      "loss": 0.3414,
      "step": 405
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.29449060559272766,
      "learning_rate": 0.0002937008940666486,
      "loss": 0.3343,
      "step": 410
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.30243268609046936,
      "learning_rate": 0.0002935992955838526,
      "loss": 0.3563,
      "step": 415
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.33709901571273804,
      "learning_rate": 0.0002934976971010566,
      "loss": 0.3515,
      "step": 420
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.31142333149909973,
      "learning_rate": 0.0002933960986182606,
      "loss": 0.3283,
      "step": 425
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2625197768211365,
      "learning_rate": 0.0002932945001354646,
      "loss": 0.333,
      "step": 430
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2784835994243622,
      "learning_rate": 0.0002931929016526686,
      "loss": 0.3186,
      "step": 435
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.29872456192970276,
      "learning_rate": 0.00029309130316987266,
      "loss": 0.3238,
      "step": 440
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.30381277203559875,
      "learning_rate": 0.0002929897046870766,
      "loss": 0.3254,
      "step": 445
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.28125131130218506,
      "learning_rate": 0.00029288810620428066,
      "loss": 0.3395,
      "step": 450
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.27010512351989746,
      "learning_rate": 0.00029278650772148466,
      "loss": 0.3174,
      "step": 455
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.31057214736938477,
      "learning_rate": 0.00029268490923868866,
      "loss": 0.3295,
      "step": 460
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.31793007254600525,
      "learning_rate": 0.0002925833107558927,
      "loss": 0.3301,
      "step": 465
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.29380592703819275,
      "learning_rate": 0.00029248171227309666,
      "loss": 0.3179,
      "step": 470
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.284062922000885,
      "learning_rate": 0.0002923801137903007,
      "loss": 0.3167,
      "step": 475
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.32572823762893677,
      "learning_rate": 0.0002922785153075047,
      "loss": 0.3264,
      "step": 480
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.28368979692459106,
      "learning_rate": 0.0002921769168247087,
      "loss": 0.3294,
      "step": 485
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2977259159088135,
      "learning_rate": 0.00029207531834191277,
      "loss": 0.3078,
      "step": 490
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.26772576570510864,
      "learning_rate": 0.00029197371985911676,
      "loss": 0.3183,
      "step": 495
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3056645095348358,
      "learning_rate": 0.00029187212137632076,
      "loss": 0.3199,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2941162884235382,
      "learning_rate": 0.00029177052289352476,
      "loss": 0.3235,
      "step": 505
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3120206594467163,
      "learning_rate": 0.00029166892441072876,
      "loss": 0.3091,
      "step": 510
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2751368284225464,
      "learning_rate": 0.0002915673259279328,
      "loss": 0.3128,
      "step": 515
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2682986855506897,
      "learning_rate": 0.0002914657274451368,
      "loss": 0.3117,
      "step": 520
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2967408001422882,
      "learning_rate": 0.0002913641289623408,
      "loss": 0.3246,
      "step": 525
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.35748156905174255,
      "learning_rate": 0.0002912625304795448,
      "loss": 0.3109,
      "step": 530
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3006719648838043,
      "learning_rate": 0.0002911609319967488,
      "loss": 0.3171,
      "step": 535
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2932738959789276,
      "learning_rate": 0.0002910593335139528,
      "loss": 0.3076,
      "step": 540
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.26814788579940796,
      "learning_rate": 0.00029095773503115687,
      "loss": 0.3206,
      "step": 545
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.30529096722602844,
      "learning_rate": 0.0002908561365483608,
      "loss": 0.3169,
      "step": 550
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2780701816082001,
      "learning_rate": 0.00029075453806556487,
      "loss": 0.3089,
      "step": 555
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.26898014545440674,
      "learning_rate": 0.00029065293958276887,
      "loss": 0.3107,
      "step": 560
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2900438606739044,
      "learning_rate": 0.00029055134109997287,
      "loss": 0.3078,
      "step": 565
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.27368488907814026,
      "learning_rate": 0.0002904497426171769,
      "loss": 0.2998,
      "step": 570
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.27730593085289,
      "learning_rate": 0.00029034814413438087,
      "loss": 0.3164,
      "step": 575
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2854602038860321,
      "learning_rate": 0.0002902465456515849,
      "loss": 0.312,
      "step": 580
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.26575252413749695,
      "learning_rate": 0.0002901449471687889,
      "loss": 0.3083,
      "step": 585
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3421761691570282,
      "learning_rate": 0.0002900433486859929,
      "loss": 0.3179,
      "step": 590
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2891044616699219,
      "learning_rate": 0.000289941750203197,
      "loss": 0.2976,
      "step": 595
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.27801281213760376,
      "learning_rate": 0.0002898401517204009,
      "loss": 0.3096,
      "step": 600
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.29712989926338196,
      "eval_runtime": 12.3053,
      "eval_samples_per_second": 8.127,
      "eval_steps_per_second": 1.056,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2754206657409668,
      "learning_rate": 0.000289738553237605,
      "loss": 0.308,
      "step": 605
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.288983553647995,
      "learning_rate": 0.000289636954754809,
      "loss": 0.316,
      "step": 610
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.27974647283554077,
      "learning_rate": 0.000289535356272013,
      "loss": 0.3063,
      "step": 615
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3045344650745392,
      "learning_rate": 0.00028943375778921703,
      "loss": 0.3029,
      "step": 620
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.25926971435546875,
      "learning_rate": 0.000289332159306421,
      "loss": 0.3031,
      "step": 625
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.25620490312576294,
      "learning_rate": 0.00028923056082362503,
      "loss": 0.3063,
      "step": 630
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.27874755859375,
      "learning_rate": 0.00028912896234082903,
      "loss": 0.3041,
      "step": 635
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.288215696811676,
      "learning_rate": 0.00028902736385803303,
      "loss": 0.3,
      "step": 640
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.31874948740005493,
      "learning_rate": 0.00028892576537523703,
      "loss": 0.3118,
      "step": 645
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.28620895743370056,
      "learning_rate": 0.00028882416689244103,
      "loss": 0.3057,
      "step": 650
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2894764840602875,
      "learning_rate": 0.000288722568409645,
      "loss": 0.3091,
      "step": 655
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.27565813064575195,
      "learning_rate": 0.0002886209699268491,
      "loss": 0.3159,
      "step": 660
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2892993986606598,
      "learning_rate": 0.0002885193714440531,
      "loss": 0.3125,
      "step": 665
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2798107862472534,
      "learning_rate": 0.0002884177729612571,
      "loss": 0.2896,
      "step": 670
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.26676225662231445,
      "learning_rate": 0.0002883161744784611,
      "loss": 0.2956,
      "step": 675
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2838878631591797,
      "learning_rate": 0.0002882145759956651,
      "loss": 0.3066,
      "step": 680
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.269385427236557,
      "learning_rate": 0.00028811297751286913,
      "loss": 0.2996,
      "step": 685
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2781241238117218,
      "learning_rate": 0.00028801137903007313,
      "loss": 0.3033,
      "step": 690
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.27543795108795166,
      "learning_rate": 0.00028790978054727713,
      "loss": 0.2977,
      "step": 695
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.28557753562927246,
      "learning_rate": 0.00028780818206448113,
      "loss": 0.3147,
      "step": 700
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2690766751766205,
      "learning_rate": 0.00028770658358168513,
      "loss": 0.3136,
      "step": 705
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2519524097442627,
      "learning_rate": 0.0002876049850988892,
      "loss": 0.3007,
      "step": 710
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.24959467351436615,
      "learning_rate": 0.0002875033866160932,
      "loss": 0.3008,
      "step": 715
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2784428894519806,
      "learning_rate": 0.0002874017881332972,
      "loss": 0.2965,
      "step": 720
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.24098925292491913,
      "learning_rate": 0.0002873001896505012,
      "loss": 0.2923,
      "step": 725
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3058353364467621,
      "learning_rate": 0.0002871985911677052,
      "loss": 0.2944,
      "step": 730
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.27578169107437134,
      "learning_rate": 0.0002870969926849092,
      "loss": 0.3051,
      "step": 735
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2571694850921631,
      "learning_rate": 0.00028699539420211324,
      "loss": 0.2965,
      "step": 740
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2668609321117401,
      "learning_rate": 0.00028689379571931724,
      "loss": 0.2913,
      "step": 745
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.26302921772003174,
      "learning_rate": 0.00028679219723652124,
      "loss": 0.3016,
      "step": 750
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.26236653327941895,
      "learning_rate": 0.00028669059875372524,
      "loss": 0.2937,
      "step": 755
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2513827979564667,
      "learning_rate": 0.00028658900027092924,
      "loss": 0.2874,
      "step": 760
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.25812673568725586,
      "learning_rate": 0.0002864874017881333,
      "loss": 0.292,
      "step": 765
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2511657774448395,
      "learning_rate": 0.0002863858033053373,
      "loss": 0.2943,
      "step": 770
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.25071981549263,
      "learning_rate": 0.0002862842048225413,
      "loss": 0.2942,
      "step": 775
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.25916507840156555,
      "learning_rate": 0.0002861826063397453,
      "loss": 0.2902,
      "step": 780
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25229546427726746,
      "learning_rate": 0.0002860810078569493,
      "loss": 0.3011,
      "step": 785
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24823273718357086,
      "learning_rate": 0.00028597940937415334,
      "loss": 0.2891,
      "step": 790
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.26781269907951355,
      "learning_rate": 0.00028587781089135734,
      "loss": 0.2924,
      "step": 795
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25578930974006653,
      "learning_rate": 0.00028577621240856134,
      "loss": 0.2886,
      "step": 800
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.2818317115306854,
      "eval_runtime": 12.3036,
      "eval_samples_per_second": 8.128,
      "eval_steps_per_second": 1.057,
      "step": 800
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.305196613073349,
      "learning_rate": 0.00028567461392576534,
      "loss": 0.296,
      "step": 805
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.26198452711105347,
      "learning_rate": 0.00028557301544296934,
      "loss": 0.3003,
      "step": 810
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2635304033756256,
      "learning_rate": 0.0002854714169601734,
      "loss": 0.2867,
      "step": 815
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2704898416996002,
      "learning_rate": 0.0002853698184773774,
      "loss": 0.2931,
      "step": 820
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25407689809799194,
      "learning_rate": 0.0002852682199945814,
      "loss": 0.3028,
      "step": 825
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25594159960746765,
      "learning_rate": 0.0002851666215117854,
      "loss": 0.2872,
      "step": 830
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2586744725704193,
      "learning_rate": 0.0002850650230289894,
      "loss": 0.2859,
      "step": 835
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3052383363246918,
      "learning_rate": 0.0002849634245461934,
      "loss": 0.3001,
      "step": 840
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24875006079673767,
      "learning_rate": 0.00028486182606339745,
      "loss": 0.2854,
      "step": 845
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2706153690814972,
      "learning_rate": 0.00028476022758060145,
      "loss": 0.288,
      "step": 850
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2663736641407013,
      "learning_rate": 0.00028465862909780545,
      "loss": 0.29,
      "step": 855
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2729572355747223,
      "learning_rate": 0.00028455703061500945,
      "loss": 0.2941,
      "step": 860
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23409169912338257,
      "learning_rate": 0.00028445543213221345,
      "loss": 0.2862,
      "step": 865
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2797766327857971,
      "learning_rate": 0.0002843538336494175,
      "loss": 0.2963,
      "step": 870
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24316848814487457,
      "learning_rate": 0.0002842522351666215,
      "loss": 0.2832,
      "step": 875
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24747200310230255,
      "learning_rate": 0.0002841506366838255,
      "loss": 0.2834,
      "step": 880
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22033442556858063,
      "learning_rate": 0.0002840490382010295,
      "loss": 0.2833,
      "step": 885
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23479671776294708,
      "learning_rate": 0.0002839474397182335,
      "loss": 0.2847,
      "step": 890
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23535002768039703,
      "learning_rate": 0.00028384584123543756,
      "loss": 0.2766,
      "step": 895
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22143539786338806,
      "learning_rate": 0.00028374424275264156,
      "loss": 0.2811,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2601207494735718,
      "learning_rate": 0.00028364264426984555,
      "loss": 0.2953,
      "step": 905
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24363000690937042,
      "learning_rate": 0.00028354104578704955,
      "loss": 0.2854,
      "step": 910
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24608926475048065,
      "learning_rate": 0.00028343944730425355,
      "loss": 0.2819,
      "step": 915
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2556568682193756,
      "learning_rate": 0.00028333784882145755,
      "loss": 0.2853,
      "step": 920
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24566423892974854,
      "learning_rate": 0.0002832362503386616,
      "loss": 0.2924,
      "step": 925
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.24681071937084198,
      "learning_rate": 0.00028313465185586555,
      "loss": 0.2873,
      "step": 930
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2419748604297638,
      "learning_rate": 0.0002830330533730696,
      "loss": 0.2964,
      "step": 935
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2158072143793106,
      "learning_rate": 0.0002829314548902736,
      "loss": 0.2977,
      "step": 940
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.24088534712791443,
      "learning_rate": 0.0002828298564074776,
      "loss": 0.2745,
      "step": 945
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.22450335323810577,
      "learning_rate": 0.00028272825792468166,
      "loss": 0.2861,
      "step": 950
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2663620114326477,
      "learning_rate": 0.0002826266594418856,
      "loss": 0.2854,
      "step": 955
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26673251390457153,
      "learning_rate": 0.00028252506095908966,
      "loss": 0.2921,
      "step": 960
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26899775862693787,
      "learning_rate": 0.00028242346247629366,
      "loss": 0.2951,
      "step": 965
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.22309932112693787,
      "learning_rate": 0.00028232186399349766,
      "loss": 0.2781,
      "step": 970
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2314191460609436,
      "learning_rate": 0.0002822202655107017,
      "loss": 0.2848,
      "step": 975
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.23904862999916077,
      "learning_rate": 0.00028211866702790566,
      "loss": 0.2913,
      "step": 980
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2577751576900482,
      "learning_rate": 0.0002820170685451097,
      "loss": 0.2761,
      "step": 985
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2491120994091034,
      "learning_rate": 0.0002819154700623137,
      "loss": 0.2936,
      "step": 990
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2237999141216278,
      "learning_rate": 0.0002818138715795177,
      "loss": 0.2936,
      "step": 995
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.29155758023262024,
      "learning_rate": 0.00028171227309672177,
      "loss": 0.2959,
      "step": 1000
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.2727009356021881,
      "eval_runtime": 12.3063,
      "eval_samples_per_second": 8.126,
      "eval_steps_per_second": 1.056,
      "step": 1000
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.24035096168518066,
      "learning_rate": 0.0002816106746139257,
      "loss": 0.2744,
      "step": 1005
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.26444342732429504,
      "learning_rate": 0.00028150907613112977,
      "loss": 0.2781,
      "step": 1010
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.23802758753299713,
      "learning_rate": 0.00028140747764833377,
      "loss": 0.3003,
      "step": 1015
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2297137975692749,
      "learning_rate": 0.00028130587916553777,
      "loss": 0.2696,
      "step": 1020
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.23059026896953583,
      "learning_rate": 0.00028120428068274177,
      "loss": 0.2851,
      "step": 1025
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.25436627864837646,
      "learning_rate": 0.0002811026821999458,
      "loss": 0.2831,
      "step": 1030
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.24200686812400818,
      "learning_rate": 0.00028100108371714976,
      "loss": 0.2839,
      "step": 1035
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.22957190871238708,
      "learning_rate": 0.0002808994852343538,
      "loss": 0.2877,
      "step": 1040
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2192709594964981,
      "learning_rate": 0.0002807978867515578,
      "loss": 0.2847,
      "step": 1045
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.271533727645874,
      "learning_rate": 0.0002806962882687618,
      "loss": 0.2856,
      "step": 1050
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.22596955299377441,
      "learning_rate": 0.00028059468978596587,
      "loss": 0.2904,
      "step": 1055
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2609614431858063,
      "learning_rate": 0.0002804930913031698,
      "loss": 0.2849,
      "step": 1060
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2631189227104187,
      "learning_rate": 0.00028039149282037387,
      "loss": 0.2723,
      "step": 1065
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.23618295788764954,
      "learning_rate": 0.00028028989433757787,
      "loss": 0.2818,
      "step": 1070
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.22890914976596832,
      "learning_rate": 0.00028018829585478187,
      "loss": 0.2734,
      "step": 1075
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.25022876262664795,
      "learning_rate": 0.0002800866973719859,
      "loss": 0.2791,
      "step": 1080
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2506817579269409,
      "learning_rate": 0.00027998509888918987,
      "loss": 0.2809,
      "step": 1085
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.24070186913013458,
      "learning_rate": 0.0002798835004063939,
      "loss": 0.2726,
      "step": 1090
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.27000701427459717,
      "learning_rate": 0.0002797819019235979,
      "loss": 0.2897,
      "step": 1095
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.22540788352489471,
      "learning_rate": 0.0002796803034408019,
      "loss": 0.279,
      "step": 1100
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.20963551104068756,
      "learning_rate": 0.0002795787049580059,
      "loss": 0.2792,
      "step": 1105
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2579374611377716,
      "learning_rate": 0.0002794771064752099,
      "loss": 0.2773,
      "step": 1110
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.20543645322322845,
      "learning_rate": 0.0002793755079924139,
      "loss": 0.2851,
      "step": 1115
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.23362958431243896,
      "learning_rate": 0.000279273909509618,
      "loss": 0.281,
      "step": 1120
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.22429165244102478,
      "learning_rate": 0.000279172311026822,
      "loss": 0.2724,
      "step": 1125
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.23475630581378937,
      "learning_rate": 0.000279070712544026,
      "loss": 0.2672,
      "step": 1130
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.21952709555625916,
      "learning_rate": 0.00027896911406123,
      "loss": 0.2725,
      "step": 1135
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.25355151295661926,
      "learning_rate": 0.000278867515578434,
      "loss": 0.276,
      "step": 1140
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.22758375108242035,
      "learning_rate": 0.00027876591709563803,
      "loss": 0.2737,
      "step": 1145
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2628103494644165,
      "learning_rate": 0.00027866431861284203,
      "loss": 0.2793,
      "step": 1150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.22073400020599365,
      "learning_rate": 0.00027856272013004603,
      "loss": 0.2789,
      "step": 1155
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2452145665884018,
      "learning_rate": 0.00027846112164725003,
      "loss": 0.2649,
      "step": 1160
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.22480766475200653,
      "learning_rate": 0.00027835952316445403,
      "loss": 0.2807,
      "step": 1165
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.25027042627334595,
      "learning_rate": 0.0002782579246816581,
      "loss": 0.2796,
      "step": 1170
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21540005505084991,
      "learning_rate": 0.0002781563261988621,
      "loss": 0.2789,
      "step": 1175
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.25589555501937866,
      "learning_rate": 0.0002780547277160661,
      "loss": 0.2707,
      "step": 1180
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21909378468990326,
      "learning_rate": 0.0002779531292332701,
      "loss": 0.2635,
      "step": 1185
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.23224273324012756,
      "learning_rate": 0.0002778515307504741,
      "loss": 0.2726,
      "step": 1190
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.22022998332977295,
      "learning_rate": 0.00027774993226767814,
      "loss": 0.2781,
      "step": 1195
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2429237812757492,
      "learning_rate": 0.00027764833378488213,
      "loss": 0.2853,
      "step": 1200
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.26592308282852173,
      "eval_runtime": 12.3037,
      "eval_samples_per_second": 8.128,
      "eval_steps_per_second": 1.057,
      "step": 1200
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.24666579067707062,
      "learning_rate": 0.00027754673530208613,
      "loss": 0.2732,
      "step": 1205
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21129348874092102,
      "learning_rate": 0.00027744513681929013,
      "loss": 0.2664,
      "step": 1210
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21084243059158325,
      "learning_rate": 0.00027734353833649413,
      "loss": 0.2668,
      "step": 1215
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.23231476545333862,
      "learning_rate": 0.00027724193985369813,
      "loss": 0.273,
      "step": 1220
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.20393376052379608,
      "learning_rate": 0.0002771403413709022,
      "loss": 0.2786,
      "step": 1225
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.21081364154815674,
      "learning_rate": 0.0002770387428881062,
      "loss": 0.2879,
      "step": 1230
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.23577342927455902,
      "learning_rate": 0.0002769371444053102,
      "loss": 0.2895,
      "step": 1235
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.20597510039806366,
      "learning_rate": 0.0002768355459225142,
      "loss": 0.2765,
      "step": 1240
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2322896420955658,
      "learning_rate": 0.0002767339474397182,
      "loss": 0.2668,
      "step": 1245
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.25251710414886475,
      "learning_rate": 0.00027663234895692224,
      "loss": 0.2789,
      "step": 1250
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.23603233695030212,
      "learning_rate": 0.00027653075047412624,
      "loss": 0.2744,
      "step": 1255
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.22260290384292603,
      "learning_rate": 0.00027642915199133024,
      "loss": 0.2735,
      "step": 1260
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.22880202531814575,
      "learning_rate": 0.00027632755350853424,
      "loss": 0.2813,
      "step": 1265
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.21680113673210144,
      "learning_rate": 0.00027622595502573824,
      "loss": 0.2708,
      "step": 1270
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2329041212797165,
      "learning_rate": 0.0002761243565429423,
      "loss": 0.2671,
      "step": 1275
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.21163833141326904,
      "learning_rate": 0.0002760227580601463,
      "loss": 0.2789,
      "step": 1280
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.24641092121601105,
      "learning_rate": 0.0002759211595773503,
      "loss": 0.2661,
      "step": 1285
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2253793179988861,
      "learning_rate": 0.0002758195610945543,
      "loss": 0.2777,
      "step": 1290
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.20523789525032043,
      "learning_rate": 0.0002757179626117583,
      "loss": 0.2735,
      "step": 1295
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2213050276041031,
      "learning_rate": 0.00027561636412896235,
      "loss": 0.273,
      "step": 1300
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.22014714777469635,
      "learning_rate": 0.00027551476564616635,
      "loss": 0.2639,
      "step": 1305
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.23636668920516968,
      "learning_rate": 0.00027541316716337035,
      "loss": 0.2747,
      "step": 1310
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.21255803108215332,
      "learning_rate": 0.00027531156868057435,
      "loss": 0.2809,
      "step": 1315
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.20689645409584045,
      "learning_rate": 0.00027520997019777834,
      "loss": 0.2715,
      "step": 1320
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.24749307334423065,
      "learning_rate": 0.00027510837171498234,
      "loss": 0.2787,
      "step": 1325
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.21364779770374298,
      "learning_rate": 0.0002750067732321864,
      "loss": 0.2853,
      "step": 1330
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.19483420252799988,
      "learning_rate": 0.0002749051747493904,
      "loss": 0.2668,
      "step": 1335
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.29946213960647583,
      "learning_rate": 0.0002748035762665944,
      "loss": 0.2809,
      "step": 1340
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2317553013563156,
      "learning_rate": 0.0002747019777837984,
      "loss": 0.2828,
      "step": 1345
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.22471082210540771,
      "learning_rate": 0.0002746003793010024,
      "loss": 0.2705,
      "step": 1350
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.20184320211410522,
      "learning_rate": 0.00027449878081820645,
      "loss": 0.272,
      "step": 1355
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2277628779411316,
      "learning_rate": 0.00027439718233541045,
      "loss": 0.286,
      "step": 1360
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.20224091410636902,
      "learning_rate": 0.00027429558385261445,
      "loss": 0.2699,
      "step": 1365
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.2076975554227829,
      "learning_rate": 0.00027419398536981845,
      "loss": 0.2655,
      "step": 1370
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.21611271798610687,
      "learning_rate": 0.00027409238688702245,
      "loss": 0.2738,
      "step": 1375
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.2152356058359146,
      "learning_rate": 0.0002739907884042265,
      "loss": 0.2687,
      "step": 1380
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.22848527133464813,
      "learning_rate": 0.0002738891899214305,
      "loss": 0.2693,
      "step": 1385
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.20246657729148865,
      "learning_rate": 0.0002737875914386345,
      "loss": 0.2792,
      "step": 1390
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.21359945833683014,
      "learning_rate": 0.0002736859929558385,
      "loss": 0.2759,
      "step": 1395
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.2036340981721878,
      "learning_rate": 0.0002735843944730425,
      "loss": 0.2709,
      "step": 1400
    },
    {
      "epoch": 0.19,
      "eval_loss": 0.2592082917690277,
      "eval_runtime": 12.2958,
      "eval_samples_per_second": 8.133,
      "eval_steps_per_second": 1.057,
      "step": 1400
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.21285207569599152,
      "learning_rate": 0.0002734827959902465,
      "loss": 0.2704,
      "step": 1405
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.19943533837795258,
      "learning_rate": 0.00027338119750745056,
      "loss": 0.2735,
      "step": 1410
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.21176965534687042,
      "learning_rate": 0.0002732795990246545,
      "loss": 0.2707,
      "step": 1415
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.20971228182315826,
      "learning_rate": 0.00027317800054185856,
      "loss": 0.2643,
      "step": 1420
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.20292061567306519,
      "learning_rate": 0.00027307640205906256,
      "loss": 0.2569,
      "step": 1425
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.21374031901359558,
      "learning_rate": 0.00027297480357626656,
      "loss": 0.2896,
      "step": 1430
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.2224927842617035,
      "learning_rate": 0.0002728732050934706,
      "loss": 0.2683,
      "step": 1435
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.21604947745800018,
      "learning_rate": 0.00027277160661067455,
      "loss": 0.279,
      "step": 1440
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.22384506464004517,
      "learning_rate": 0.0002726700081278786,
      "loss": 0.2765,
      "step": 1445
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.22571922838687897,
      "learning_rate": 0.0002725684096450826,
      "loss": 0.2673,
      "step": 1450
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.19903910160064697,
      "learning_rate": 0.0002724668111622866,
      "loss": 0.2866,
      "step": 1455
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.22117865085601807,
      "learning_rate": 0.00027236521267949066,
      "loss": 0.2774,
      "step": 1460
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2261994481086731,
      "learning_rate": 0.0002722636141966946,
      "loss": 0.2674,
      "step": 1465
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.21827079355716705,
      "learning_rate": 0.00027216201571389866,
      "loss": 0.2918,
      "step": 1470
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.20145313441753387,
      "learning_rate": 0.00027206041723110266,
      "loss": 0.2698,
      "step": 1475
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2155677080154419,
      "learning_rate": 0.00027195881874830666,
      "loss": 0.2724,
      "step": 1480
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.22373729944229126,
      "learning_rate": 0.0002718572202655107,
      "loss": 0.2596,
      "step": 1485
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.24669592082500458,
      "learning_rate": 0.00027175562178271466,
      "loss": 0.2784,
      "step": 1490
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.23486748337745667,
      "learning_rate": 0.0002716540232999187,
      "loss": 0.2547,
      "step": 1495
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.21350617706775665,
      "learning_rate": 0.0002715524248171227,
      "loss": 0.2805,
      "step": 1500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.24070824682712555,
      "learning_rate": 0.0002714508263343267,
      "loss": 0.2715,
      "step": 1505
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2044273465871811,
      "learning_rate": 0.0002713492278515307,
      "loss": 0.2759,
      "step": 1510
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.21404553949832916,
      "learning_rate": 0.0002712476293687347,
      "loss": 0.2759,
      "step": 1515
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.235727459192276,
      "learning_rate": 0.0002711460308859387,
      "loss": 0.2752,
      "step": 1520
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.18625414371490479,
      "learning_rate": 0.00027104443240314277,
      "loss": 0.2646,
      "step": 1525
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.2032739669084549,
      "learning_rate": 0.00027094283392034677,
      "loss": 0.2673,
      "step": 1530
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19398948550224304,
      "learning_rate": 0.00027084123543755077,
      "loss": 0.2711,
      "step": 1535
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.2337263822555542,
      "learning_rate": 0.0002707396369547548,
      "loss": 0.2681,
      "step": 1540
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19815795123577118,
      "learning_rate": 0.00027063803847195877,
      "loss": 0.2727,
      "step": 1545
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.1966937929391861,
      "learning_rate": 0.0002705364399891628,
      "loss": 0.2627,
      "step": 1550
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.22283238172531128,
      "learning_rate": 0.0002704348415063668,
      "loss": 0.2716,
      "step": 1555
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.2046230435371399,
      "learning_rate": 0.0002703332430235708,
      "loss": 0.2642,
      "step": 1560
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.19280965626239777,
      "learning_rate": 0.0002702316445407749,
      "loss": 0.2808,
      "step": 1565
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.2212885469198227,
      "learning_rate": 0.0002701300460579788,
      "loss": 0.2679,
      "step": 1570
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.21211875975131989,
      "learning_rate": 0.00027002844757518287,
      "loss": 0.2626,
      "step": 1575
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.2069082111120224,
      "learning_rate": 0.00026992684909238687,
      "loss": 0.2668,
      "step": 1580
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.22577856481075287,
      "learning_rate": 0.00026982525060959087,
      "loss": 0.2695,
      "step": 1585
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.2387985736131668,
      "learning_rate": 0.00026972365212679487,
      "loss": 0.2701,
      "step": 1590
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.20286740362644196,
      "learning_rate": 0.00026962205364399887,
      "loss": 0.2571,
      "step": 1595
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.19984804093837738,
      "learning_rate": 0.00026952045516120287,
      "loss": 0.2711,
      "step": 1600
    },
    {
      "epoch": 0.22,
      "eval_loss": 0.25648993253707886,
      "eval_runtime": 12.2852,
      "eval_samples_per_second": 8.14,
      "eval_steps_per_second": 1.058,
      "step": 1600
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.19702336192131042,
      "learning_rate": 0.0002694188566784069,
      "loss": 0.2795,
      "step": 1605
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.2123250663280487,
      "learning_rate": 0.0002693172581956109,
      "loss": 0.2651,
      "step": 1610
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.19830439984798431,
      "learning_rate": 0.0002692156597128149,
      "loss": 0.2536,
      "step": 1615
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.20233504474163055,
      "learning_rate": 0.0002691140612300189,
      "loss": 0.2796,
      "step": 1620
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.20235545933246613,
      "learning_rate": 0.0002690124627472229,
      "loss": 0.2595,
      "step": 1625
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3202354609966278,
      "learning_rate": 0.000268910864264427,
      "loss": 0.2637,
      "step": 1630
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.18465261161327362,
      "learning_rate": 0.000268809265781631,
      "loss": 0.2637,
      "step": 1635
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.20459860563278198,
      "learning_rate": 0.000268707667298835,
      "loss": 0.2676,
      "step": 1640
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.20253409445285797,
      "learning_rate": 0.000268606068816039,
      "loss": 0.2671,
      "step": 1645
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1984989047050476,
      "learning_rate": 0.000268504470333243,
      "loss": 0.259,
      "step": 1650
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.2272859364748001,
      "learning_rate": 0.00026840287185044703,
      "loss": 0.2752,
      "step": 1655
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1750895082950592,
      "learning_rate": 0.00026830127336765103,
      "loss": 0.263,
      "step": 1660
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.243991419672966,
      "learning_rate": 0.00026819967488485503,
      "loss": 0.2689,
      "step": 1665
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.19370216131210327,
      "learning_rate": 0.00026809807640205903,
      "loss": 0.2549,
      "step": 1670
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.19627118110656738,
      "learning_rate": 0.00026799647791926303,
      "loss": 0.262,
      "step": 1675
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.20665444433689117,
      "learning_rate": 0.0002678948794364671,
      "loss": 0.2709,
      "step": 1680
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.18918736279010773,
      "learning_rate": 0.0002677932809536711,
      "loss": 0.257,
      "step": 1685
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1973564326763153,
      "learning_rate": 0.0002676916824708751,
      "loss": 0.2581,
      "step": 1690
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.23398704826831818,
      "learning_rate": 0.0002675900839880791,
      "loss": 0.2568,
      "step": 1695
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.20025016367435455,
      "learning_rate": 0.0002674884855052831,
      "loss": 0.2616,
      "step": 1700
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.2089821696281433,
      "learning_rate": 0.0002673868870224871,
      "loss": 0.2647,
      "step": 1705
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1957477629184723,
      "learning_rate": 0.00026728528853969114,
      "loss": 0.2641,
      "step": 1710
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.21158884465694427,
      "learning_rate": 0.00026718369005689514,
      "loss": 0.2687,
      "step": 1715
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.2026355117559433,
      "learning_rate": 0.00026708209157409914,
      "loss": 0.2762,
      "step": 1720
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.202509343624115,
      "learning_rate": 0.00026698049309130314,
      "loss": 0.2575,
      "step": 1725
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1901150643825531,
      "learning_rate": 0.00026687889460850714,
      "loss": 0.2641,
      "step": 1730
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.19584713876247406,
      "learning_rate": 0.0002667772961257112,
      "loss": 0.2597,
      "step": 1735
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.2015831023454666,
      "learning_rate": 0.0002666756976429152,
      "loss": 0.2668,
      "step": 1740
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1994868516921997,
      "learning_rate": 0.0002665740991601192,
      "loss": 0.2758,
      "step": 1745
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.20934145152568817,
      "learning_rate": 0.0002664725006773232,
      "loss": 0.2602,
      "step": 1750
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.20581366121768951,
      "learning_rate": 0.0002663709021945272,
      "loss": 0.272,
      "step": 1755
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.22032701969146729,
      "learning_rate": 0.00026626930371173124,
      "loss": 0.2593,
      "step": 1760
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1814325451850891,
      "learning_rate": 0.00026616770522893524,
      "loss": 0.2592,
      "step": 1765
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.18272805213928223,
      "learning_rate": 0.00026606610674613924,
      "loss": 0.2537,
      "step": 1770
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.2235194444656372,
      "learning_rate": 0.00026596450826334324,
      "loss": 0.2648,
      "step": 1775
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.21267354488372803,
      "learning_rate": 0.00026586290978054724,
      "loss": 0.264,
      "step": 1780
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.20583948493003845,
      "learning_rate": 0.00026576131129775124,
      "loss": 0.266,
      "step": 1785
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.19991901516914368,
      "learning_rate": 0.0002656597128149553,
      "loss": 0.2621,
      "step": 1790
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.18557074666023254,
      "learning_rate": 0.0002655581143321593,
      "loss": 0.2713,
      "step": 1795
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.18875449895858765,
      "learning_rate": 0.0002654565158493633,
      "loss": 0.2541,
      "step": 1800
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.25140392780303955,
      "eval_runtime": 12.3001,
      "eval_samples_per_second": 8.13,
      "eval_steps_per_second": 1.057,
      "step": 1800
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.2046477496623993,
      "learning_rate": 0.0002653549173665673,
      "loss": 0.2615,
      "step": 1805
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.20840993523597717,
      "learning_rate": 0.0002652533188837713,
      "loss": 0.2589,
      "step": 1810
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.19576162099838257,
      "learning_rate": 0.00026515172040097535,
      "loss": 0.2703,
      "step": 1815
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.1947680562734604,
      "learning_rate": 0.00026505012191817935,
      "loss": 0.2622,
      "step": 1820
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18854224681854248,
      "learning_rate": 0.00026494852343538335,
      "loss": 0.261,
      "step": 1825
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.20182234048843384,
      "learning_rate": 0.00026484692495258735,
      "loss": 0.2605,
      "step": 1830
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.20205336809158325,
      "learning_rate": 0.00026474532646979135,
      "loss": 0.2614,
      "step": 1835
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.2249860167503357,
      "learning_rate": 0.0002646437279869954,
      "loss": 0.2681,
      "step": 1840
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18588697910308838,
      "learning_rate": 0.0002645421295041994,
      "loss": 0.2665,
      "step": 1845
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.20156504213809967,
      "learning_rate": 0.0002644405310214034,
      "loss": 0.2572,
      "step": 1850
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.19122399389743805,
      "learning_rate": 0.0002643389325386074,
      "loss": 0.2832,
      "step": 1855
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.19107355177402496,
      "learning_rate": 0.0002642373340558114,
      "loss": 0.2698,
      "step": 1860
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.1920955926179886,
      "learning_rate": 0.00026413573557301545,
      "loss": 0.2519,
      "step": 1865
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.2191297858953476,
      "learning_rate": 0.00026403413709021945,
      "loss": 0.2769,
      "step": 1870
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.2077614814043045,
      "learning_rate": 0.00026393253860742345,
      "loss": 0.2502,
      "step": 1875
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.21407003700733185,
      "learning_rate": 0.00026383094012462745,
      "loss": 0.2589,
      "step": 1880
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.2067207247018814,
      "learning_rate": 0.00026372934164183145,
      "loss": 0.2563,
      "step": 1885
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.20787449181079865,
      "learning_rate": 0.00026362774315903545,
      "loss": 0.2515,
      "step": 1890
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.204551562666893,
      "learning_rate": 0.0002635261446762395,
      "loss": 0.2646,
      "step": 1895
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.20503127574920654,
      "learning_rate": 0.00026342454619344345,
      "loss": 0.2616,
      "step": 1900
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.19874081015586853,
      "learning_rate": 0.0002633229477106475,
      "loss": 0.2645,
      "step": 1905
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.1841653287410736,
      "learning_rate": 0.0002632213492278515,
      "loss": 0.2517,
      "step": 1910
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.19878603518009186,
      "learning_rate": 0.0002631197507450555,
      "loss": 0.2659,
      "step": 1915
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2004578560590744,
      "learning_rate": 0.00026301815226225956,
      "loss": 0.2589,
      "step": 1920
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.18949444591999054,
      "learning_rate": 0.0002629165537794635,
      "loss": 0.2612,
      "step": 1925
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.19172179698944092,
      "learning_rate": 0.00026281495529666756,
      "loss": 0.2573,
      "step": 1930
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.193929985165596,
      "learning_rate": 0.00026271335681387156,
      "loss": 0.2611,
      "step": 1935
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.19958901405334473,
      "learning_rate": 0.00026261175833107556,
      "loss": 0.2714,
      "step": 1940
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.20094285905361176,
      "learning_rate": 0.0002625101598482796,
      "loss": 0.2671,
      "step": 1945
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2067757546901703,
      "learning_rate": 0.00026240856136548356,
      "loss": 0.2696,
      "step": 1950
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.18237410485744476,
      "learning_rate": 0.0002623069628826876,
      "loss": 0.2676,
      "step": 1955
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2073286771774292,
      "learning_rate": 0.0002622053643998916,
      "loss": 0.2617,
      "step": 1960
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.18579788506031036,
      "learning_rate": 0.0002621037659170956,
      "loss": 0.273,
      "step": 1965
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.18909133970737457,
      "learning_rate": 0.00026200216743429966,
      "loss": 0.2662,
      "step": 1970
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.21160924434661865,
      "learning_rate": 0.0002619005689515036,
      "loss": 0.2639,
      "step": 1975
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.20150528848171234,
      "learning_rate": 0.00026179897046870766,
      "loss": 0.2618,
      "step": 1980
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1657039076089859,
      "learning_rate": 0.00026169737198591166,
      "loss": 0.2632,
      "step": 1985
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1999085545539856,
      "learning_rate": 0.00026159577350311566,
      "loss": 0.2558,
      "step": 1990
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.21045717597007751,
      "learning_rate": 0.00026149417502031966,
      "loss": 0.258,
      "step": 1995
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.18754766881465912,
      "learning_rate": 0.00026139257653752366,
      "loss": 0.2597,
      "step": 2000
    },
    {
      "epoch": 0.27,
      "eval_loss": 0.2482108175754547,
      "eval_runtime": 12.305,
      "eval_samples_per_second": 8.127,
      "eval_steps_per_second": 1.056,
      "step": 2000
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.19244836270809174,
      "learning_rate": 0.00026129097805472766,
      "loss": 0.2705,
      "step": 2005
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1926967203617096,
      "learning_rate": 0.0002611893795719317,
      "loss": 0.2595,
      "step": 2010
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.21094992756843567,
      "learning_rate": 0.0002610877810891357,
      "loss": 0.2585,
      "step": 2015
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.20198264718055725,
      "learning_rate": 0.0002609861826063397,
      "loss": 0.2551,
      "step": 2020
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.20436041057109833,
      "learning_rate": 0.0002608845841235437,
      "loss": 0.2627,
      "step": 2025
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.22923725843429565,
      "learning_rate": 0.0002607829856407477,
      "loss": 0.2689,
      "step": 2030
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.1842641830444336,
      "learning_rate": 0.00026068138715795177,
      "loss": 0.2596,
      "step": 2035
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.18866868317127228,
      "learning_rate": 0.00026057978867515577,
      "loss": 0.2605,
      "step": 2040
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.19298672676086426,
      "learning_rate": 0.00026047819019235977,
      "loss": 0.2641,
      "step": 2045
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.20212766528129578,
      "learning_rate": 0.0002603765917095638,
      "loss": 0.2458,
      "step": 2050
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.20593833923339844,
      "learning_rate": 0.00026027499322676777,
      "loss": 0.2543,
      "step": 2055
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1971839964389801,
      "learning_rate": 0.0002601733947439718,
      "loss": 0.2563,
      "step": 2060
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.19380813837051392,
      "learning_rate": 0.0002600717962611758,
      "loss": 0.2563,
      "step": 2065
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2101459950208664,
      "learning_rate": 0.0002599701977783798,
      "loss": 0.256,
      "step": 2070
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.24970924854278564,
      "learning_rate": 0.0002598685992955838,
      "loss": 0.2575,
      "step": 2075
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.20313873887062073,
      "learning_rate": 0.0002597670008127878,
      "loss": 0.2519,
      "step": 2080
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.19877085089683533,
      "learning_rate": 0.0002596654023299918,
      "loss": 0.258,
      "step": 2085
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.1853448897600174,
      "learning_rate": 0.0002595638038471959,
      "loss": 0.2431,
      "step": 2090
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2121291160583496,
      "learning_rate": 0.0002594622053643999,
      "loss": 0.2604,
      "step": 2095
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.21836549043655396,
      "learning_rate": 0.0002593606068816039,
      "loss": 0.2693,
      "step": 2100
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.21749015152454376,
      "learning_rate": 0.0002592590083988079,
      "loss": 0.2686,
      "step": 2105
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.20106899738311768,
      "learning_rate": 0.00025915740991601187,
      "loss": 0.2507,
      "step": 2110
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.17992985248565674,
      "learning_rate": 0.0002590558114332159,
      "loss": 0.2516,
      "step": 2115
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.19717413187026978,
      "learning_rate": 0.0002589542129504199,
      "loss": 0.2566,
      "step": 2120
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.20568442344665527,
      "learning_rate": 0.0002588526144676239,
      "loss": 0.2592,
      "step": 2125
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.18440023064613342,
      "learning_rate": 0.0002587510159848279,
      "loss": 0.2439,
      "step": 2130
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2004944384098053,
      "learning_rate": 0.0002586494175020319,
      "loss": 0.2604,
      "step": 2135
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.18413583934307098,
      "learning_rate": 0.000258547819019236,
      "loss": 0.2694,
      "step": 2140
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.18201632797718048,
      "learning_rate": 0.00025844622053644,
      "loss": 0.2501,
      "step": 2145
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.17760534584522247,
      "learning_rate": 0.000258344622053644,
      "loss": 0.2643,
      "step": 2150
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.21510548889636993,
      "learning_rate": 0.000258243023570848,
      "loss": 0.2601,
      "step": 2155
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.16388468444347382,
      "learning_rate": 0.000258141425088052,
      "loss": 0.2583,
      "step": 2160
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1981387436389923,
      "learning_rate": 0.00025803982660525603,
      "loss": 0.2672,
      "step": 2165
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.20975130796432495,
      "learning_rate": 0.00025793822812246003,
      "loss": 0.2657,
      "step": 2170
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.17256441712379456,
      "learning_rate": 0.00025783662963966403,
      "loss": 0.2616,
      "step": 2175
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1880323737859726,
      "learning_rate": 0.00025773503115686803,
      "loss": 0.2484,
      "step": 2180
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.19105461239814758,
      "learning_rate": 0.00025763343267407203,
      "loss": 0.2522,
      "step": 2185
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.19086232781410217,
      "learning_rate": 0.00025753183419127603,
      "loss": 0.2639,
      "step": 2190
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.19123977422714233,
      "learning_rate": 0.0002574302357084801,
      "loss": 0.2751,
      "step": 2195
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1812516450881958,
      "learning_rate": 0.0002573286372256841,
      "loss": 0.2619,
      "step": 2200
    },
    {
      "epoch": 0.3,
      "eval_loss": 0.2478485256433487,
      "eval_runtime": 12.2921,
      "eval_samples_per_second": 8.135,
      "eval_steps_per_second": 1.058,
      "step": 2200
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.20303387939929962,
      "learning_rate": 0.0002572270387428881,
      "loss": 0.2522,
      "step": 2205
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1948269009590149,
      "learning_rate": 0.0002571254402600921,
      "loss": 0.251,
      "step": 2210
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.18492849171161652,
      "learning_rate": 0.0002570238417772961,
      "loss": 0.26,
      "step": 2215
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.19328449666500092,
      "learning_rate": 0.00025692224329450014,
      "loss": 0.2723,
      "step": 2220
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.19622015953063965,
      "learning_rate": 0.00025682064481170414,
      "loss": 0.2675,
      "step": 2225
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1836652159690857,
      "learning_rate": 0.00025671904632890814,
      "loss": 0.2544,
      "step": 2230
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1910206377506256,
      "learning_rate": 0.00025661744784611214,
      "loss": 0.2552,
      "step": 2235
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.19485297799110413,
      "learning_rate": 0.00025651584936331614,
      "loss": 0.2655,
      "step": 2240
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1838773638010025,
      "learning_rate": 0.0002564142508805202,
      "loss": 0.2563,
      "step": 2245
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.20702216029167175,
      "learning_rate": 0.0002563126523977242,
      "loss": 0.2557,
      "step": 2250
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.19870154559612274,
      "learning_rate": 0.0002562110539149282,
      "loss": 0.252,
      "step": 2255
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.18548864126205444,
      "learning_rate": 0.0002561094554321322,
      "loss": 0.2621,
      "step": 2260
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.19349467754364014,
      "learning_rate": 0.0002560078569493362,
      "loss": 0.2552,
      "step": 2265
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1822122186422348,
      "learning_rate": 0.0002559062584665402,
      "loss": 0.2533,
      "step": 2270
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1933515965938568,
      "learning_rate": 0.00025580465998374424,
      "loss": 0.2541,
      "step": 2275
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.20113179087638855,
      "learning_rate": 0.0002557030615009482,
      "loss": 0.2742,
      "step": 2280
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.19395793974399567,
      "learning_rate": 0.00025560146301815224,
      "loss": 0.2477,
      "step": 2285
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1992723047733307,
      "learning_rate": 0.00025549986453535624,
      "loss": 0.2529,
      "step": 2290
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1803741604089737,
      "learning_rate": 0.00025539826605256024,
      "loss": 0.2729,
      "step": 2295
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.2061365395784378,
      "learning_rate": 0.0002552966675697643,
      "loss": 0.2571,
      "step": 2300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1985805481672287,
      "learning_rate": 0.00025519506908696824,
      "loss": 0.2552,
      "step": 2305
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.21141517162322998,
      "learning_rate": 0.0002550934706041723,
      "loss": 0.2662,
      "step": 2310
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.18233077228069305,
      "learning_rate": 0.0002549918721213763,
      "loss": 0.2582,
      "step": 2315
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1684114933013916,
      "learning_rate": 0.0002548902736385803,
      "loss": 0.258,
      "step": 2320
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.18270161747932434,
      "learning_rate": 0.00025478867515578435,
      "loss": 0.2672,
      "step": 2325
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.19651809334754944,
      "learning_rate": 0.00025468707667298835,
      "loss": 0.2566,
      "step": 2330
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.2009243667125702,
      "learning_rate": 0.00025458547819019235,
      "loss": 0.2494,
      "step": 2335
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.20473405718803406,
      "learning_rate": 0.00025448387970739635,
      "loss": 0.2505,
      "step": 2340
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.19196607172489166,
      "learning_rate": 0.00025438228122460035,
      "loss": 0.2622,
      "step": 2345
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1873009353876114,
      "learning_rate": 0.0002542806827418044,
      "loss": 0.2541,
      "step": 2350
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18869967758655548,
      "learning_rate": 0.0002541790842590084,
      "loss": 0.2664,
      "step": 2355
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.17427994310855865,
      "learning_rate": 0.0002540774857762124,
      "loss": 0.2591,
      "step": 2360
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18237607181072235,
      "learning_rate": 0.0002539758872934164,
      "loss": 0.2558,
      "step": 2365
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.17199330031871796,
      "learning_rate": 0.0002538742888106204,
      "loss": 0.2577,
      "step": 2370
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.18295706808567047,
      "learning_rate": 0.0002537726903278244,
      "loss": 0.2553,
      "step": 2375
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.20268990099430084,
      "learning_rate": 0.00025367109184502845,
      "loss": 0.2597,
      "step": 2380
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.19634294509887695,
      "learning_rate": 0.0002535694933622324,
      "loss": 0.2496,
      "step": 2385
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.17848090827465057,
      "learning_rate": 0.00025346789487943645,
      "loss": 0.2488,
      "step": 2390
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1794751137495041,
      "learning_rate": 0.00025336629639664045,
      "loss": 0.2607,
      "step": 2395
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.194253072142601,
      "learning_rate": 0.00025326469791384445,
      "loss": 0.2566,
      "step": 2400
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.24402254819869995,
      "eval_runtime": 12.2987,
      "eval_samples_per_second": 8.131,
      "eval_steps_per_second": 1.057,
      "step": 2400
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.19586779177188873,
      "learning_rate": 0.0002531630994310485,
      "loss": 0.262,
      "step": 2405
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.19643861055374146,
      "learning_rate": 0.00025306150094825245,
      "loss": 0.249,
      "step": 2410
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1904502809047699,
      "learning_rate": 0.0002529599024654565,
      "loss": 0.2593,
      "step": 2415
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1667182594537735,
      "learning_rate": 0.0002528583039826605,
      "loss": 0.2495,
      "step": 2420
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.21734848618507385,
      "learning_rate": 0.0002527567054998645,
      "loss": 0.2641,
      "step": 2425
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.17592892050743103,
      "learning_rate": 0.00025265510701706856,
      "loss": 0.2463,
      "step": 2430
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.18994873762130737,
      "learning_rate": 0.0002525535085342725,
      "loss": 0.2648,
      "step": 2435
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.19109219312667847,
      "learning_rate": 0.00025245191005147656,
      "loss": 0.2573,
      "step": 2440
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.2008972018957138,
      "learning_rate": 0.00025235031156868056,
      "loss": 0.259,
      "step": 2445
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.18993020057678223,
      "learning_rate": 0.00025224871308588456,
      "loss": 0.2698,
      "step": 2450
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1805599182844162,
      "learning_rate": 0.00025214711460308856,
      "loss": 0.2596,
      "step": 2455
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.19104808568954468,
      "learning_rate": 0.00025204551612029256,
      "loss": 0.2628,
      "step": 2460
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.17378094792366028,
      "learning_rate": 0.00025194391763749656,
      "loss": 0.2562,
      "step": 2465
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.18030838668346405,
      "learning_rate": 0.0002518423191547006,
      "loss": 0.2665,
      "step": 2470
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.18488964438438416,
      "learning_rate": 0.0002517407206719046,
      "loss": 0.2625,
      "step": 2475
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.18965817987918854,
      "learning_rate": 0.0002516391221891086,
      "loss": 0.2572,
      "step": 2480
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.2051977664232254,
      "learning_rate": 0.0002515375237063126,
      "loss": 0.2499,
      "step": 2485
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17788249254226685,
      "learning_rate": 0.0002514359252235166,
      "loss": 0.2437,
      "step": 2490
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.21219402551651,
      "learning_rate": 0.00025133432674072066,
      "loss": 0.2548,
      "step": 2495
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17971138656139374,
      "learning_rate": 0.00025123272825792466,
      "loss": 0.2555,
      "step": 2500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.18754449486732483,
      "learning_rate": 0.00025113112977512866,
      "loss": 0.2517,
      "step": 2505
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1689254641532898,
      "learning_rate": 0.00025102953129233266,
      "loss": 0.2529,
      "step": 2510
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.18810579180717468,
      "learning_rate": 0.00025092793280953666,
      "loss": 0.2569,
      "step": 2515
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.18790863454341888,
      "learning_rate": 0.0002508263343267407,
      "loss": 0.2577,
      "step": 2520
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.20801787078380585,
      "learning_rate": 0.0002507247358439447,
      "loss": 0.2461,
      "step": 2525
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.18065346777439117,
      "learning_rate": 0.0002506231373611487,
      "loss": 0.248,
      "step": 2530
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.18262098729610443,
      "learning_rate": 0.0002505215388783527,
      "loss": 0.2514,
      "step": 2535
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17021530866622925,
      "learning_rate": 0.0002504199403955567,
      "loss": 0.2603,
      "step": 2540
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1584012806415558,
      "learning_rate": 0.00025031834191276077,
      "loss": 0.257,
      "step": 2545
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1888911873102188,
      "learning_rate": 0.00025021674342996477,
      "loss": 0.2392,
      "step": 2550
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1949920952320099,
      "learning_rate": 0.00025011514494716877,
      "loss": 0.2501,
      "step": 2555
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.17533837258815765,
      "learning_rate": 0.00025001354646437277,
      "loss": 0.2587,
      "step": 2560
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.16936136782169342,
      "learning_rate": 0.00024991194798157677,
      "loss": 0.255,
      "step": 2565
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.2007422000169754,
      "learning_rate": 0.00024981034949878077,
      "loss": 0.2558,
      "step": 2570
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.18628443777561188,
      "learning_rate": 0.0002497087510159848,
      "loss": 0.2499,
      "step": 2575
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.16019493341445923,
      "learning_rate": 0.0002496071525331888,
      "loss": 0.2424,
      "step": 2580
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.21997356414794922,
      "learning_rate": 0.0002495055540503928,
      "loss": 0.259,
      "step": 2585
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.17862749099731445,
      "learning_rate": 0.0002494039555675968,
      "loss": 0.2484,
      "step": 2590
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.17560885846614838,
      "learning_rate": 0.0002493023570848008,
      "loss": 0.2655,
      "step": 2595
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.18447564542293549,
      "learning_rate": 0.0002492007586020049,
      "loss": 0.2467,
      "step": 2600
    },
    {
      "epoch": 0.35,
      "eval_loss": 0.242324098944664,
      "eval_runtime": 12.3014,
      "eval_samples_per_second": 8.129,
      "eval_steps_per_second": 1.057,
      "step": 2600
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.16165363788604736,
      "learning_rate": 0.0002490991601192089,
      "loss": 0.2567,
      "step": 2605
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1774147003889084,
      "learning_rate": 0.0002489975616364129,
      "loss": 0.2539,
      "step": 2610
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.18216507136821747,
      "learning_rate": 0.0002488959631536169,
      "loss": 0.2564,
      "step": 2615
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.18483175337314606,
      "learning_rate": 0.0002487943646708209,
      "loss": 0.261,
      "step": 2620
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.19852250814437866,
      "learning_rate": 0.00024869276618802493,
      "loss": 0.254,
      "step": 2625
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1746564358472824,
      "learning_rate": 0.00024859116770522893,
      "loss": 0.2548,
      "step": 2630
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.1885330080986023,
      "learning_rate": 0.00024848956922243293,
      "loss": 0.2549,
      "step": 2635
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.18050487339496613,
      "learning_rate": 0.00024838797073963693,
      "loss": 0.2709,
      "step": 2640
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.19132086634635925,
      "learning_rate": 0.0002482863722568409,
      "loss": 0.2534,
      "step": 2645
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.17415733635425568,
      "learning_rate": 0.0002481847737740449,
      "loss": 0.2485,
      "step": 2650
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1957874447107315,
      "learning_rate": 0.000248083175291249,
      "loss": 0.2481,
      "step": 2655
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.17196692526340485,
      "learning_rate": 0.000247981576808453,
      "loss": 0.2608,
      "step": 2660
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.18243621289730072,
      "learning_rate": 0.000247879978325657,
      "loss": 0.2603,
      "step": 2665
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.18193721771240234,
      "learning_rate": 0.000247778379842861,
      "loss": 0.252,
      "step": 2670
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.20471711456775665,
      "learning_rate": 0.000247676781360065,
      "loss": 0.254,
      "step": 2675
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.17053110897541046,
      "learning_rate": 0.00024757518287726903,
      "loss": 0.2537,
      "step": 2680
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.19138970971107483,
      "learning_rate": 0.00024747358439447303,
      "loss": 0.243,
      "step": 2685
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.19743627309799194,
      "learning_rate": 0.00024737198591167703,
      "loss": 0.254,
      "step": 2690
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.17528006434440613,
      "learning_rate": 0.00024727038742888103,
      "loss": 0.2494,
      "step": 2695
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1813046783208847,
      "learning_rate": 0.00024716878894608503,
      "loss": 0.2587,
      "step": 2700
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.19698774814605713,
      "learning_rate": 0.0002470671904632891,
      "loss": 0.2472,
      "step": 2705
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.2020009607076645,
      "learning_rate": 0.0002469655919804931,
      "loss": 0.2437,
      "step": 2710
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1864217221736908,
      "learning_rate": 0.0002468639934976971,
      "loss": 0.2547,
      "step": 2715
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.18467606604099274,
      "learning_rate": 0.0002467623950149011,
      "loss": 0.2798,
      "step": 2720
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1947091966867447,
      "learning_rate": 0.0002466607965321051,
      "loss": 0.2563,
      "step": 2725
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.17293980717658997,
      "learning_rate": 0.00024655919804930914,
      "loss": 0.2588,
      "step": 2730
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.21924160420894623,
      "learning_rate": 0.00024645759956651314,
      "loss": 0.2594,
      "step": 2735
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.17374208569526672,
      "learning_rate": 0.00024635600108371714,
      "loss": 0.2585,
      "step": 2740
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.19012832641601562,
      "learning_rate": 0.00024625440260092114,
      "loss": 0.2481,
      "step": 2745
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.16893915832042694,
      "learning_rate": 0.00024615280411812514,
      "loss": 0.2502,
      "step": 2750
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.17357100546360016,
      "learning_rate": 0.00024605120563532914,
      "loss": 0.2528,
      "step": 2755
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1609600931406021,
      "learning_rate": 0.0002459496071525332,
      "loss": 0.2459,
      "step": 2760
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.17287681996822357,
      "learning_rate": 0.00024584800866973714,
      "loss": 0.2493,
      "step": 2765
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.17565149068832397,
      "learning_rate": 0.0002457464101869412,
      "loss": 0.2418,
      "step": 2770
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1882326453924179,
      "learning_rate": 0.0002456448117041452,
      "loss": 0.2455,
      "step": 2775
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1849382370710373,
      "learning_rate": 0.0002455432132213492,
      "loss": 0.2532,
      "step": 2780
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.19385699927806854,
      "learning_rate": 0.00024544161473855324,
      "loss": 0.2374,
      "step": 2785
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.18085871636867523,
      "learning_rate": 0.0002453400162557572,
      "loss": 0.2724,
      "step": 2790
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.18732841312885284,
      "learning_rate": 0.00024523841777296124,
      "loss": 0.2482,
      "step": 2795
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.16831041872501373,
      "learning_rate": 0.00024513681929016524,
      "loss": 0.2555,
      "step": 2800
    },
    {
      "epoch": 0.38,
      "eval_loss": 0.24163231253623962,
      "eval_runtime": 12.2944,
      "eval_samples_per_second": 8.134,
      "eval_steps_per_second": 1.057,
      "step": 2800
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.17001807689666748,
      "learning_rate": 0.00024503522080736924,
      "loss": 0.2531,
      "step": 2805
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1809462159872055,
      "learning_rate": 0.0002449336223245733,
      "loss": 0.266,
      "step": 2810
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1752198189496994,
      "learning_rate": 0.00024483202384177724,
      "loss": 0.2476,
      "step": 2815
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.16689330339431763,
      "learning_rate": 0.0002447304253589813,
      "loss": 0.2513,
      "step": 2820
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.18069769442081451,
      "learning_rate": 0.0002446288268761853,
      "loss": 0.2547,
      "step": 2825
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.18813762068748474,
      "learning_rate": 0.0002445272283933893,
      "loss": 0.2536,
      "step": 2830
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.16656161844730377,
      "learning_rate": 0.00024442562991059335,
      "loss": 0.2451,
      "step": 2835
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.16108357906341553,
      "learning_rate": 0.00024432403142779735,
      "loss": 0.2412,
      "step": 2840
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1803802251815796,
      "learning_rate": 0.00024422243294500135,
      "loss": 0.2402,
      "step": 2845
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1899743527173996,
      "learning_rate": 0.00024412083446220535,
      "loss": 0.2524,
      "step": 2850
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1898098886013031,
      "learning_rate": 0.00024401923597940935,
      "loss": 0.254,
      "step": 2855
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.17601528763771057,
      "learning_rate": 0.00024391763749661338,
      "loss": 0.2441,
      "step": 2860
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18515922129154205,
      "learning_rate": 0.00024381603901381738,
      "loss": 0.2391,
      "step": 2865
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1896974742412567,
      "learning_rate": 0.00024371444053102138,
      "loss": 0.2456,
      "step": 2870
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1953539103269577,
      "learning_rate": 0.00024361284204822537,
      "loss": 0.2584,
      "step": 2875
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.19047017395496368,
      "learning_rate": 0.0002435112435654294,
      "loss": 0.2453,
      "step": 2880
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18162541091442108,
      "learning_rate": 0.00024340964508263343,
      "loss": 0.2605,
      "step": 2885
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18908195197582245,
      "learning_rate": 0.00024330804659983743,
      "loss": 0.2536,
      "step": 2890
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.16911089420318604,
      "learning_rate": 0.00024320644811704143,
      "loss": 0.2561,
      "step": 2895
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.16349336504936218,
      "learning_rate": 0.00024310484963424543,
      "loss": 0.2624,
      "step": 2900
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.17270468175411224,
      "learning_rate": 0.00024300325115144945,
      "loss": 0.2498,
      "step": 2905
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.17888589203357697,
      "learning_rate": 0.00024290165266865348,
      "loss": 0.2603,
      "step": 2910
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.19780157506465912,
      "learning_rate": 0.00024280005418585748,
      "loss": 0.2639,
      "step": 2915
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18879634141921997,
      "learning_rate": 0.00024269845570306148,
      "loss": 0.2605,
      "step": 2920
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.18298393487930298,
      "learning_rate": 0.00024259685722026548,
      "loss": 0.2448,
      "step": 2925
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.174055278301239,
      "learning_rate": 0.0002424952587374695,
      "loss": 0.2567,
      "step": 2930
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.16904695332050323,
      "learning_rate": 0.0002423936602546735,
      "loss": 0.2592,
      "step": 2935
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1731814295053482,
      "learning_rate": 0.00024229206177187753,
      "loss": 0.2449,
      "step": 2940
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.18563860654830933,
      "learning_rate": 0.0002421904632890815,
      "loss": 0.2474,
      "step": 2945
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1909877359867096,
      "learning_rate": 0.00024208886480628553,
      "loss": 0.2526,
      "step": 2950
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.17976365983486176,
      "learning_rate": 0.00024198726632348956,
      "loss": 0.2556,
      "step": 2955
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.17223717272281647,
      "learning_rate": 0.00024188566784069356,
      "loss": 0.2641,
      "step": 2960
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1919362097978592,
      "learning_rate": 0.0002417840693578976,
      "loss": 0.2555,
      "step": 2965
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1953502595424652,
      "learning_rate": 0.00024168247087510156,
      "loss": 0.241,
      "step": 2970
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.16514447331428528,
      "learning_rate": 0.00024158087239230559,
      "loss": 0.2523,
      "step": 2975
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.19529502093791962,
      "learning_rate": 0.00024147927390950959,
      "loss": 0.24,
      "step": 2980
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.19016383588314056,
      "learning_rate": 0.0002413776754267136,
      "loss": 0.2503,
      "step": 2985
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.15335801243782043,
      "learning_rate": 0.00024127607694391764,
      "loss": 0.2475,
      "step": 2990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.17588688433170319,
      "learning_rate": 0.0002411744784611216,
      "loss": 0.2489,
      "step": 2995
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.16962747275829315,
      "learning_rate": 0.00024107287997832564,
      "loss": 0.2484,
      "step": 3000
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.2405034601688385,
      "eval_runtime": 12.2946,
      "eval_samples_per_second": 8.134,
      "eval_steps_per_second": 1.057,
      "step": 3000
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.18014949560165405,
      "learning_rate": 0.00024097128149552964,
      "loss": 0.2515,
      "step": 3005
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.22291617095470428,
      "learning_rate": 0.00024086968301273367,
      "loss": 0.2473,
      "step": 3010
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1903461515903473,
      "learning_rate": 0.00024076808452993767,
      "loss": 0.2512,
      "step": 3015
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.17915092408657074,
      "learning_rate": 0.00024066648604714166,
      "loss": 0.2549,
      "step": 3020
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.16513457894325256,
      "learning_rate": 0.00024056488756434566,
      "loss": 0.2654,
      "step": 3025
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.17437642812728882,
      "learning_rate": 0.0002404632890815497,
      "loss": 0.2558,
      "step": 3030
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.18574285507202148,
      "learning_rate": 0.00024036169059875372,
      "loss": 0.2451,
      "step": 3035
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1707177758216858,
      "learning_rate": 0.00024026009211595772,
      "loss": 0.2452,
      "step": 3040
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1825733631849289,
      "learning_rate": 0.00024015849363316172,
      "loss": 0.2563,
      "step": 3045
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1958032250404358,
      "learning_rate": 0.00024005689515036572,
      "loss": 0.243,
      "step": 3050
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.17567187547683716,
      "learning_rate": 0.00023995529666756974,
      "loss": 0.2527,
      "step": 3055
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.17699061334133148,
      "learning_rate": 0.00023985369818477374,
      "loss": 0.2506,
      "step": 3060
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.20185476541519165,
      "learning_rate": 0.00023975209970197777,
      "loss": 0.2512,
      "step": 3065
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1599763184785843,
      "learning_rate": 0.00023965050121918174,
      "loss": 0.2526,
      "step": 3070
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.16601867973804474,
      "learning_rate": 0.00023954890273638577,
      "loss": 0.2517,
      "step": 3075
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1824186146259308,
      "learning_rate": 0.0002394473042535898,
      "loss": 0.2377,
      "step": 3080
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.18225553631782532,
      "learning_rate": 0.0002393457057707938,
      "loss": 0.2383,
      "step": 3085
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17530575394630432,
      "learning_rate": 0.00023924410728799782,
      "loss": 0.2542,
      "step": 3090
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1803266555070877,
      "learning_rate": 0.00023914250880520185,
      "loss": 0.2516,
      "step": 3095
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.18100005388259888,
      "learning_rate": 0.00023904091032240582,
      "loss": 0.2733,
      "step": 3100
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.164618119597435,
      "learning_rate": 0.00023893931183960985,
      "loss": 0.2426,
      "step": 3105
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1925434023141861,
      "learning_rate": 0.00023883771335681385,
      "loss": 0.2466,
      "step": 3110
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.16717487573623657,
      "learning_rate": 0.00023873611487401788,
      "loss": 0.2402,
      "step": 3115
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.18551357090473175,
      "learning_rate": 0.00023863451639122188,
      "loss": 0.2562,
      "step": 3120
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1601029634475708,
      "learning_rate": 0.00023853291790842588,
      "loss": 0.2667,
      "step": 3125
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17144401371479034,
      "learning_rate": 0.00023843131942562988,
      "loss": 0.2564,
      "step": 3130
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.18159988522529602,
      "learning_rate": 0.0002383297209428339,
      "loss": 0.2492,
      "step": 3135
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.185903862118721,
      "learning_rate": 0.00023822812246003793,
      "loss": 0.2501,
      "step": 3140
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.17232076823711395,
      "learning_rate": 0.00023812652397724193,
      "loss": 0.2553,
      "step": 3145
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1638467013835907,
      "learning_rate": 0.00023802492549444593,
      "loss": 0.2563,
      "step": 3150
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1780070811510086,
      "learning_rate": 0.00023792332701164993,
      "loss": 0.2471,
      "step": 3155
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.17557500302791595,
      "learning_rate": 0.00023782172852885396,
      "loss": 0.2461,
      "step": 3160
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1731111854314804,
      "learning_rate": 0.00023772013004605795,
      "loss": 0.2533,
      "step": 3165
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.17465409636497498,
      "learning_rate": 0.00023761853156326198,
      "loss": 0.241,
      "step": 3170
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.18388158082962036,
      "learning_rate": 0.00023751693308046595,
      "loss": 0.2457,
      "step": 3175
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.18612945079803467,
      "learning_rate": 0.00023741533459766998,
      "loss": 0.2359,
      "step": 3180
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16275279223918915,
      "learning_rate": 0.000237313736114874,
      "loss": 0.2432,
      "step": 3185
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.18894879519939423,
      "learning_rate": 0.000237212137632078,
      "loss": 0.2444,
      "step": 3190
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16755494475364685,
      "learning_rate": 0.00023711053914928203,
      "loss": 0.2589,
      "step": 3195
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1689557582139969,
      "learning_rate": 0.000237008940666486,
      "loss": 0.2524,
      "step": 3200
    },
    {
      "epoch": 0.43,
      "eval_loss": 0.23964811861515045,
      "eval_runtime": 12.3109,
      "eval_samples_per_second": 8.123,
      "eval_steps_per_second": 1.056,
      "step": 3200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16352349519729614,
      "learning_rate": 0.00023690734218369003,
      "loss": 0.2502,
      "step": 3205
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16881640255451202,
      "learning_rate": 0.00023680574370089403,
      "loss": 0.2567,
      "step": 3210
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16935841739177704,
      "learning_rate": 0.00023670414521809806,
      "loss": 0.2431,
      "step": 3215
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16804081201553345,
      "learning_rate": 0.0002366025467353021,
      "loss": 0.251,
      "step": 3220
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.1595262736082077,
      "learning_rate": 0.00023650094825250606,
      "loss": 0.2469,
      "step": 3225
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.18626093864440918,
      "learning_rate": 0.0002363993497697101,
      "loss": 0.2635,
      "step": 3230
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1815764456987381,
      "learning_rate": 0.0002362977512869141,
      "loss": 0.2428,
      "step": 3235
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.16308796405792236,
      "learning_rate": 0.0002361961528041181,
      "loss": 0.2395,
      "step": 3240
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.18485596776008606,
      "learning_rate": 0.00023609455432132214,
      "loss": 0.2573,
      "step": 3245
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.18407858908176422,
      "learning_rate": 0.0002359929558385261,
      "loss": 0.245,
      "step": 3250
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.16654236614704132,
      "learning_rate": 0.00023589135735573014,
      "loss": 0.2512,
      "step": 3255
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.17192433774471283,
      "learning_rate": 0.00023578975887293414,
      "loss": 0.2403,
      "step": 3260
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.17556002736091614,
      "learning_rate": 0.00023568816039013817,
      "loss": 0.2468,
      "step": 3265
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.18250790238380432,
      "learning_rate": 0.00023558656190734217,
      "loss": 0.262,
      "step": 3270
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.15435431897640228,
      "learning_rate": 0.00023548496342454617,
      "loss": 0.2542,
      "step": 3275
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.18753136694431305,
      "learning_rate": 0.00023538336494175017,
      "loss": 0.2499,
      "step": 3280
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.17934396862983704,
      "learning_rate": 0.0002352817664589542,
      "loss": 0.2507,
      "step": 3285
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.17170457541942596,
      "learning_rate": 0.00023518016797615822,
      "loss": 0.2456,
      "step": 3290
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.17522968351840973,
      "learning_rate": 0.00023507856949336222,
      "loss": 0.2439,
      "step": 3295
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.16729941964149475,
      "learning_rate": 0.00023497697101056622,
      "loss": 0.2375,
      "step": 3300
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.18248251080513,
      "learning_rate": 0.00023487537252777022,
      "loss": 0.2533,
      "step": 3305
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.17756010591983795,
      "learning_rate": 0.00023477377404497424,
      "loss": 0.2411,
      "step": 3310
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.18551190197467804,
      "learning_rate": 0.00023467217556217824,
      "loss": 0.2537,
      "step": 3315
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.16618506610393524,
      "learning_rate": 0.00023457057707938227,
      "loss": 0.2504,
      "step": 3320
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.15545326471328735,
      "learning_rate": 0.00023446897859658624,
      "loss": 0.253,
      "step": 3325
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1944635510444641,
      "learning_rate": 0.00023436738011379027,
      "loss": 0.2622,
      "step": 3330
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1710900068283081,
      "learning_rate": 0.0002342657816309943,
      "loss": 0.2601,
      "step": 3335
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.159713014960289,
      "learning_rate": 0.0002341641831481983,
      "loss": 0.254,
      "step": 3340
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.16263025999069214,
      "learning_rate": 0.00023406258466540232,
      "loss": 0.2545,
      "step": 3345
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.16863545775413513,
      "learning_rate": 0.00023396098618260632,
      "loss": 0.2492,
      "step": 3350
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1653291881084442,
      "learning_rate": 0.00023385938769981032,
      "loss": 0.2432,
      "step": 3355
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.20060458779335022,
      "learning_rate": 0.00023375778921701432,
      "loss": 0.2317,
      "step": 3360
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.17216798663139343,
      "learning_rate": 0.00023365619073421835,
      "loss": 0.2479,
      "step": 3365
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1656288206577301,
      "learning_rate": 0.00023355459225142238,
      "loss": 0.241,
      "step": 3370
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.16767306625843048,
      "learning_rate": 0.00023345299376862638,
      "loss": 0.2443,
      "step": 3375
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.18505699932575226,
      "learning_rate": 0.00023335139528583038,
      "loss": 0.2314,
      "step": 3380
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.175363227725029,
      "learning_rate": 0.00023324979680303438,
      "loss": 0.2555,
      "step": 3385
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.15046878159046173,
      "learning_rate": 0.0002331481983202384,
      "loss": 0.2493,
      "step": 3390
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.18861842155456543,
      "learning_rate": 0.0002330465998374424,
      "loss": 0.2582,
      "step": 3395
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.18228550255298615,
      "learning_rate": 0.00023294500135464643,
      "loss": 0.2449,
      "step": 3400
    },
    {
      "epoch": 0.46,
      "eval_loss": 0.2384912520647049,
      "eval_runtime": 12.2975,
      "eval_samples_per_second": 8.132,
      "eval_steps_per_second": 1.057,
      "step": 3400
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1660490781068802,
      "learning_rate": 0.0002328434028718504,
      "loss": 0.2483,
      "step": 3405
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.17662803828716278,
      "learning_rate": 0.00023274180438905443,
      "loss": 0.2619,
      "step": 3410
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.17107781767845154,
      "learning_rate": 0.00023264020590625846,
      "loss": 0.2372,
      "step": 3415
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.18542423844337463,
      "learning_rate": 0.00023253860742346246,
      "loss": 0.251,
      "step": 3420
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1883622705936432,
      "learning_rate": 0.00023243700894066648,
      "loss": 0.2525,
      "step": 3425
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.16781504452228546,
      "learning_rate": 0.00023233541045787046,
      "loss": 0.2567,
      "step": 3430
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.16129352152347565,
      "learning_rate": 0.00023223381197507448,
      "loss": 0.2478,
      "step": 3435
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1781446933746338,
      "learning_rate": 0.0002321322134922785,
      "loss": 0.2585,
      "step": 3440
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.17961455881595612,
      "learning_rate": 0.0002320306150094825,
      "loss": 0.2506,
      "step": 3445
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.16122975945472717,
      "learning_rate": 0.00023192901652668654,
      "loss": 0.2505,
      "step": 3450
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.1952248215675354,
      "learning_rate": 0.0002318274180438905,
      "loss": 0.2385,
      "step": 3455
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.15693385899066925,
      "learning_rate": 0.00023172581956109453,
      "loss": 0.2504,
      "step": 3460
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1537627875804901,
      "learning_rate": 0.00023162422107829853,
      "loss": 0.2479,
      "step": 3465
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1647612601518631,
      "learning_rate": 0.00023152262259550256,
      "loss": 0.2477,
      "step": 3470
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.17169107496738434,
      "learning_rate": 0.0002314210241127066,
      "loss": 0.24,
      "step": 3475
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.16187676787376404,
      "learning_rate": 0.00023131942562991056,
      "loss": 0.2359,
      "step": 3480
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.18252794444561005,
      "learning_rate": 0.0002312178271471146,
      "loss": 0.2339,
      "step": 3485
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.16355390846729279,
      "learning_rate": 0.0002311162286643186,
      "loss": 0.2524,
      "step": 3490
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.15997199714183807,
      "learning_rate": 0.00023101463018152261,
      "loss": 0.2401,
      "step": 3495
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.16693434119224548,
      "learning_rate": 0.00023091303169872661,
      "loss": 0.2423,
      "step": 3500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.18333497643470764,
      "learning_rate": 0.0002308114332159306,
      "loss": 0.2562,
      "step": 3505
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.16507317125797272,
      "learning_rate": 0.0002307098347331346,
      "loss": 0.2512,
      "step": 3510
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.17443427443504333,
      "learning_rate": 0.00023060823625033864,
      "loss": 0.2464,
      "step": 3515
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.170567125082016,
      "learning_rate": 0.00023050663776754267,
      "loss": 0.232,
      "step": 3520
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1711597740650177,
      "learning_rate": 0.00023040503928474667,
      "loss": 0.2365,
      "step": 3525
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.17530687153339386,
      "learning_rate": 0.00023030344080195067,
      "loss": 0.253,
      "step": 3530
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.16724906861782074,
      "learning_rate": 0.00023020184231915467,
      "loss": 0.2411,
      "step": 3535
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.15010347962379456,
      "learning_rate": 0.0002301002438363587,
      "loss": 0.235,
      "step": 3540
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.15824279189109802,
      "learning_rate": 0.0002299986453535627,
      "loss": 0.2453,
      "step": 3545
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17270983755588531,
      "learning_rate": 0.00022989704687076672,
      "loss": 0.2547,
      "step": 3550
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1751978099346161,
      "learning_rate": 0.0002297954483879707,
      "loss": 0.2514,
      "step": 3555
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1596326231956482,
      "learning_rate": 0.00022969384990517472,
      "loss": 0.244,
      "step": 3560
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.18243448436260223,
      "learning_rate": 0.00022959225142237875,
      "loss": 0.2422,
      "step": 3565
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.18443632125854492,
      "learning_rate": 0.00022949065293958275,
      "loss": 0.2515,
      "step": 3570
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.36569082736968994,
      "learning_rate": 0.00022938905445678677,
      "loss": 0.2517,
      "step": 3575
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1911223828792572,
      "learning_rate": 0.00022928745597399074,
      "loss": 0.2498,
      "step": 3580
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.19169044494628906,
      "learning_rate": 0.00022918585749119477,
      "loss": 0.2458,
      "step": 3585
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17246843874454498,
      "learning_rate": 0.0002290842590083988,
      "loss": 0.2456,
      "step": 3590
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17935685813426971,
      "learning_rate": 0.0002289826605256028,
      "loss": 0.2464,
      "step": 3595
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.1714589148759842,
      "learning_rate": 0.00022888106204280683,
      "loss": 0.2564,
      "step": 3600
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.23714664578437805,
      "eval_runtime": 12.2955,
      "eval_samples_per_second": 8.133,
      "eval_steps_per_second": 1.057,
      "step": 3600
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.16757291555404663,
      "learning_rate": 0.0002287794635600108,
      "loss": 0.2508,
      "step": 3605
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1808185577392578,
      "learning_rate": 0.00022867786507721482,
      "loss": 0.2391,
      "step": 3610
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.16773001849651337,
      "learning_rate": 0.00022857626659441882,
      "loss": 0.2447,
      "step": 3615
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1702008992433548,
      "learning_rate": 0.00022847466811162285,
      "loss": 0.2427,
      "step": 3620
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1647235006093979,
      "learning_rate": 0.00022837306962882688,
      "loss": 0.2395,
      "step": 3625
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.18186908960342407,
      "learning_rate": 0.00022827147114603088,
      "loss": 0.2437,
      "step": 3630
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.18004067242145538,
      "learning_rate": 0.00022816987266323488,
      "loss": 0.2382,
      "step": 3635
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1712760478258133,
      "learning_rate": 0.00022806827418043888,
      "loss": 0.2441,
      "step": 3640
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.15789593756198883,
      "learning_rate": 0.0002279666756976429,
      "loss": 0.2438,
      "step": 3645
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.175967276096344,
      "learning_rate": 0.0002278650772148469,
      "loss": 0.2448,
      "step": 3650
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.17808972299098969,
      "learning_rate": 0.00022776347873205093,
      "loss": 0.2518,
      "step": 3655
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.15910704433918,
      "learning_rate": 0.0002276618802492549,
      "loss": 0.263,
      "step": 3660
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.17107832431793213,
      "learning_rate": 0.00022756028176645893,
      "loss": 0.2449,
      "step": 3665
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.2086041420698166,
      "learning_rate": 0.00022745868328366296,
      "loss": 0.2385,
      "step": 3670
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.17480488121509552,
      "learning_rate": 0.00022735708480086696,
      "loss": 0.2478,
      "step": 3675
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.15819832682609558,
      "learning_rate": 0.00022725548631807098,
      "loss": 0.2442,
      "step": 3680
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1686367243528366,
      "learning_rate": 0.00022715388783527496,
      "loss": 0.2303,
      "step": 3685
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.17348545789718628,
      "learning_rate": 0.00022705228935247898,
      "loss": 0.2467,
      "step": 3690
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.16009940207004547,
      "learning_rate": 0.00022695069086968298,
      "loss": 0.2422,
      "step": 3695
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1720198392868042,
      "learning_rate": 0.000226849092386887,
      "loss": 0.252,
      "step": 3700
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.18083104491233826,
      "learning_rate": 0.00022674749390409104,
      "loss": 0.2468,
      "step": 3705
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.16260549426078796,
      "learning_rate": 0.000226645895421295,
      "loss": 0.2455,
      "step": 3710
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.16759483516216278,
      "learning_rate": 0.00022654429693849904,
      "loss": 0.2474,
      "step": 3715
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.16530001163482666,
      "learning_rate": 0.00022644269845570304,
      "loss": 0.2392,
      "step": 3720
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.17677074670791626,
      "learning_rate": 0.00022634109997290706,
      "loss": 0.2512,
      "step": 3725
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1596183180809021,
      "learning_rate": 0.00022623950149011106,
      "loss": 0.2533,
      "step": 3730
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.1811777800321579,
      "learning_rate": 0.00022613790300731506,
      "loss": 0.2257,
      "step": 3735
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.16608770191669464,
      "learning_rate": 0.00022603630452451906,
      "loss": 0.2424,
      "step": 3740
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.17085595428943634,
      "learning_rate": 0.0002259347060417231,
      "loss": 0.2454,
      "step": 3745
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.17749443650245667,
      "learning_rate": 0.00022583310755892711,
      "loss": 0.2471,
      "step": 3750
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.17087484896183014,
      "learning_rate": 0.00022573150907613111,
      "loss": 0.2415,
      "step": 3755
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.17720989882946014,
      "learning_rate": 0.00022562991059333511,
      "loss": 0.2552,
      "step": 3760
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.17014743387699127,
      "learning_rate": 0.00022552831211053911,
      "loss": 0.2583,
      "step": 3765
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.18298140168190002,
      "learning_rate": 0.00022542671362774314,
      "loss": 0.2306,
      "step": 3770
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1651124805212021,
      "learning_rate": 0.00022532511514494717,
      "loss": 0.2422,
      "step": 3775
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1642538458108902,
      "learning_rate": 0.00022522351666215117,
      "loss": 0.245,
      "step": 3780
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1596280187368393,
      "learning_rate": 0.00022512191817935517,
      "loss": 0.2418,
      "step": 3785
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.15696501731872559,
      "learning_rate": 0.00022502031969655917,
      "loss": 0.2334,
      "step": 3790
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1673743575811386,
      "learning_rate": 0.0002249187212137632,
      "loss": 0.254,
      "step": 3795
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.15337131917476654,
      "learning_rate": 0.0002248171227309672,
      "loss": 0.2386,
      "step": 3800
    },
    {
      "epoch": 0.51,
      "eval_loss": 0.2360733598470688,
      "eval_runtime": 12.2976,
      "eval_samples_per_second": 8.132,
      "eval_steps_per_second": 1.057,
      "step": 3800
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.17422686517238617,
      "learning_rate": 0.00022471552424817122,
      "loss": 0.2424,
      "step": 3805
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.15206357836723328,
      "learning_rate": 0.0002246139257653752,
      "loss": 0.2397,
      "step": 3810
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1558268964290619,
      "learning_rate": 0.00022451232728257922,
      "loss": 0.2491,
      "step": 3815
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.1522149294614792,
      "learning_rate": 0.00022441072879978325,
      "loss": 0.2523,
      "step": 3820
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.16141889989376068,
      "learning_rate": 0.00022430913031698725,
      "loss": 0.2347,
      "step": 3825
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1717132180929184,
      "learning_rate": 0.00022420753183419127,
      "loss": 0.2387,
      "step": 3830
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.17516173422336578,
      "learning_rate": 0.00022410593335139525,
      "loss": 0.2334,
      "step": 3835
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.179032102227211,
      "learning_rate": 0.00022400433486859927,
      "loss": 0.2468,
      "step": 3840
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.17203691601753235,
      "learning_rate": 0.00022390273638580327,
      "loss": 0.2438,
      "step": 3845
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.18959634006023407,
      "learning_rate": 0.0002238011379030073,
      "loss": 0.2491,
      "step": 3850
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.16874860227108002,
      "learning_rate": 0.00022369953942021133,
      "loss": 0.2347,
      "step": 3855
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.22042807936668396,
      "learning_rate": 0.0002235979409374153,
      "loss": 0.2427,
      "step": 3860
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1724814474582672,
      "learning_rate": 0.00022349634245461933,
      "loss": 0.2441,
      "step": 3865
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.16783761978149414,
      "learning_rate": 0.00022339474397182332,
      "loss": 0.2347,
      "step": 3870
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1459752470254898,
      "learning_rate": 0.00022329314548902735,
      "loss": 0.24,
      "step": 3875
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1529707908630371,
      "learning_rate": 0.00022319154700623135,
      "loss": 0.2349,
      "step": 3880
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.20065084099769592,
      "learning_rate": 0.00022308994852343538,
      "loss": 0.2465,
      "step": 3885
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.1617782562971115,
      "learning_rate": 0.00022298835004063935,
      "loss": 0.2418,
      "step": 3890
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.18126115202903748,
      "learning_rate": 0.00022288675155784338,
      "loss": 0.2585,
      "step": 3895
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.17828606069087982,
      "learning_rate": 0.0002227851530750474,
      "loss": 0.244,
      "step": 3900
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.18011711537837982,
      "learning_rate": 0.0002226835545922514,
      "loss": 0.2385,
      "step": 3905
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1687854826450348,
      "learning_rate": 0.00022258195610945543,
      "loss": 0.2468,
      "step": 3910
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.17731182277202606,
      "learning_rate": 0.0002224803576266594,
      "loss": 0.2459,
      "step": 3915
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.15948709845542908,
      "learning_rate": 0.00022237875914386343,
      "loss": 0.241,
      "step": 3920
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1777995228767395,
      "learning_rate": 0.00022227716066106743,
      "loss": 0.2591,
      "step": 3925
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1662699580192566,
      "learning_rate": 0.00022217556217827146,
      "loss": 0.2357,
      "step": 3930
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1758671998977661,
      "learning_rate": 0.00022207396369547548,
      "loss": 0.2559,
      "step": 3935
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.18980184197425842,
      "learning_rate": 0.00022197236521267946,
      "loss": 0.2398,
      "step": 3940
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.17525289952754974,
      "learning_rate": 0.00022187076672988348,
      "loss": 0.2438,
      "step": 3945
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.18125545978546143,
      "learning_rate": 0.00022176916824708748,
      "loss": 0.2348,
      "step": 3950
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1690027415752411,
      "learning_rate": 0.0002216675697642915,
      "loss": 0.252,
      "step": 3955
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.17177437245845795,
      "learning_rate": 0.00022156597128149554,
      "loss": 0.2572,
      "step": 3960
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.1758427768945694,
      "learning_rate": 0.0002214643727986995,
      "loss": 0.2577,
      "step": 3965
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.17004148662090302,
      "learning_rate": 0.00022136277431590354,
      "loss": 0.2424,
      "step": 3970
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.18298378586769104,
      "learning_rate": 0.00022126117583310754,
      "loss": 0.2416,
      "step": 3975
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.17978447675704956,
      "learning_rate": 0.00022115957735031156,
      "loss": 0.2415,
      "step": 3980
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.15650464594364166,
      "learning_rate": 0.00022105797886751556,
      "loss": 0.2482,
      "step": 3985
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1712990403175354,
      "learning_rate": 0.00022095638038471956,
      "loss": 0.2418,
      "step": 3990
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.16427454352378845,
      "learning_rate": 0.00022085478190192356,
      "loss": 0.2409,
      "step": 3995
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.15927311778068542,
      "learning_rate": 0.0002207531834191276,
      "loss": 0.2249,
      "step": 4000
    },
    {
      "epoch": 0.54,
      "eval_loss": 0.23517465591430664,
      "eval_runtime": 12.3036,
      "eval_samples_per_second": 8.128,
      "eval_steps_per_second": 1.057,
      "step": 4000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.20029571652412415,
      "learning_rate": 0.00022065158493633162,
      "loss": 0.2447,
      "step": 4005
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.16891634464263916,
      "learning_rate": 0.00022054998645353562,
      "loss": 0.245,
      "step": 4010
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.16396257281303406,
      "learning_rate": 0.00022044838797073961,
      "loss": 0.2378,
      "step": 4015
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1592952162027359,
      "learning_rate": 0.00022034678948794361,
      "loss": 0.2518,
      "step": 4020
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.1542845368385315,
      "learning_rate": 0.00022024519100514764,
      "loss": 0.2464,
      "step": 4025
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.17361420392990112,
      "learning_rate": 0.00022014359252235164,
      "loss": 0.2395,
      "step": 4030
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.16076776385307312,
      "learning_rate": 0.00022004199403955567,
      "loss": 0.2359,
      "step": 4035
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.19089709222316742,
      "learning_rate": 0.00021994039555675964,
      "loss": 0.2587,
      "step": 4040
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.16137906908988953,
      "learning_rate": 0.00021983879707396367,
      "loss": 0.2439,
      "step": 4045
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.16442443430423737,
      "learning_rate": 0.0002197371985911677,
      "loss": 0.2425,
      "step": 4050
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.16719909012317657,
      "learning_rate": 0.0002196356001083717,
      "loss": 0.2407,
      "step": 4055
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1782766580581665,
      "learning_rate": 0.00021953400162557572,
      "loss": 0.2408,
      "step": 4060
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.19097670912742615,
      "learning_rate": 0.0002194324031427797,
      "loss": 0.2484,
      "step": 4065
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1493108868598938,
      "learning_rate": 0.00021933080465998372,
      "loss": 0.2624,
      "step": 4070
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.15810389816761017,
      "learning_rate": 0.00021922920617718772,
      "loss": 0.2464,
      "step": 4075
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.17765302956104279,
      "learning_rate": 0.00021912760769439175,
      "loss": 0.2341,
      "step": 4080
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.16492556035518646,
      "learning_rate": 0.00021902600921159577,
      "loss": 0.2386,
      "step": 4085
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.176290825009346,
      "learning_rate": 0.00021892441072879975,
      "loss": 0.257,
      "step": 4090
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1782921552658081,
      "learning_rate": 0.00021882281224600377,
      "loss": 0.2407,
      "step": 4095
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.18707576394081116,
      "learning_rate": 0.00021872121376320777,
      "loss": 0.2475,
      "step": 4100
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.179130420088768,
      "learning_rate": 0.0002186196152804118,
      "loss": 0.2522,
      "step": 4105
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1615089476108551,
      "learning_rate": 0.00021851801679761583,
      "loss": 0.2466,
      "step": 4110
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.1546735167503357,
      "learning_rate": 0.0002184164183148198,
      "loss": 0.2329,
      "step": 4115
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.18308766186237335,
      "learning_rate": 0.00021831481983202383,
      "loss": 0.2304,
      "step": 4120
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.16682910919189453,
      "learning_rate": 0.00021821322134922783,
      "loss": 0.2372,
      "step": 4125
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1601707637310028,
      "learning_rate": 0.00021811162286643185,
      "loss": 0.238,
      "step": 4130
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.15327051281929016,
      "learning_rate": 0.00021801002438363585,
      "loss": 0.2492,
      "step": 4135
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.17599335312843323,
      "learning_rate": 0.00021790842590083988,
      "loss": 0.2445,
      "step": 4140
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.15612930059432983,
      "learning_rate": 0.00021780682741804385,
      "loss": 0.2451,
      "step": 4145
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16448505222797394,
      "learning_rate": 0.00021770522893524788,
      "loss": 0.2342,
      "step": 4150
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.15810833871364594,
      "learning_rate": 0.0002176036304524519,
      "loss": 0.2479,
      "step": 4155
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.19977973401546478,
      "learning_rate": 0.0002175020319696559,
      "loss": 0.2392,
      "step": 4160
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16892921924591064,
      "learning_rate": 0.00021740043348685993,
      "loss": 0.2519,
      "step": 4165
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16878287494182587,
      "learning_rate": 0.0002172988350040639,
      "loss": 0.2321,
      "step": 4170
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.16988277435302734,
      "learning_rate": 0.00021719723652126793,
      "loss": 0.2476,
      "step": 4175
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.15359017252922058,
      "learning_rate": 0.00021709563803847193,
      "loss": 0.2581,
      "step": 4180
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.17459435760974884,
      "learning_rate": 0.00021699403955567596,
      "loss": 0.2381,
      "step": 4185
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.17646841704845428,
      "learning_rate": 0.00021689244107287998,
      "loss": 0.2504,
      "step": 4190
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.1588377058506012,
      "learning_rate": 0.00021679084259008396,
      "loss": 0.2395,
      "step": 4195
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.17634987831115723,
      "learning_rate": 0.00021668924410728798,
      "loss": 0.2494,
      "step": 4200
    },
    {
      "epoch": 0.57,
      "eval_loss": 0.23266977071762085,
      "eval_runtime": 12.2909,
      "eval_samples_per_second": 8.136,
      "eval_steps_per_second": 1.058,
      "step": 4200
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1602282077074051,
      "learning_rate": 0.00021658764562449198,
      "loss": 0.2478,
      "step": 4205
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1732931137084961,
      "learning_rate": 0.000216486047141696,
      "loss": 0.2505,
      "step": 4210
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.16726626455783844,
      "learning_rate": 0.0002163844486589,
      "loss": 0.2415,
      "step": 4215
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.18008336424827576,
      "learning_rate": 0.000216282850176104,
      "loss": 0.2408,
      "step": 4220
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1712811440229416,
      "learning_rate": 0.000216181251693308,
      "loss": 0.2458,
      "step": 4225
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1687261462211609,
      "learning_rate": 0.00021607965321051204,
      "loss": 0.249,
      "step": 4230
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1618497222661972,
      "learning_rate": 0.00021597805472771606,
      "loss": 0.2485,
      "step": 4235
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1636444479227066,
      "learning_rate": 0.00021587645624492006,
      "loss": 0.2484,
      "step": 4240
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.18659549951553345,
      "learning_rate": 0.00021577485776212406,
      "loss": 0.2396,
      "step": 4245
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.17064884305000305,
      "learning_rate": 0.00021567325927932806,
      "loss": 0.2347,
      "step": 4250
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.16105058789253235,
      "learning_rate": 0.0002155716607965321,
      "loss": 0.252,
      "step": 4255
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.17989297211170197,
      "learning_rate": 0.0002154700623137361,
      "loss": 0.2498,
      "step": 4260
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.16833043098449707,
      "learning_rate": 0.00021536846383094012,
      "loss": 0.2376,
      "step": 4265
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.1776365041732788,
      "learning_rate": 0.0002152668653481441,
      "loss": 0.2317,
      "step": 4270
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1847742795944214,
      "learning_rate": 0.00021516526686534812,
      "loss": 0.235,
      "step": 4275
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1586572825908661,
      "learning_rate": 0.00021506366838255214,
      "loss": 0.2341,
      "step": 4280
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.19657452404499054,
      "learning_rate": 0.00021496206989975614,
      "loss": 0.2473,
      "step": 4285
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.15440048277378082,
      "learning_rate": 0.00021486047141696017,
      "loss": 0.2368,
      "step": 4290
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1819678395986557,
      "learning_rate": 0.00021475887293416414,
      "loss": 0.2343,
      "step": 4295
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1670610010623932,
      "learning_rate": 0.00021465727445136817,
      "loss": 0.2421,
      "step": 4300
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.17252567410469055,
      "learning_rate": 0.0002145556759685722,
      "loss": 0.2425,
      "step": 4305
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.16730009019374847,
      "learning_rate": 0.0002144540774857762,
      "loss": 0.2342,
      "step": 4310
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.16007225215435028,
      "learning_rate": 0.00021435247900298022,
      "loss": 0.2332,
      "step": 4315
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.16888925433158875,
      "learning_rate": 0.0002142508805201842,
      "loss": 0.2489,
      "step": 4320
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.20747488737106323,
      "learning_rate": 0.00021414928203738822,
      "loss": 0.2477,
      "step": 4325
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1682901680469513,
      "learning_rate": 0.00021404768355459222,
      "loss": 0.2347,
      "step": 4330
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.17091256380081177,
      "learning_rate": 0.00021394608507179625,
      "loss": 0.2382,
      "step": 4335
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1726868599653244,
      "learning_rate": 0.00021384448658900027,
      "loss": 0.2454,
      "step": 4340
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.17264480888843536,
      "learning_rate": 0.00021374288810620425,
      "loss": 0.2484,
      "step": 4345
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.18055576086044312,
      "learning_rate": 0.00021364128962340827,
      "loss": 0.238,
      "step": 4350
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.15016421675682068,
      "learning_rate": 0.00021353969114061227,
      "loss": 0.2356,
      "step": 4355
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.16559289395809174,
      "learning_rate": 0.0002134380926578163,
      "loss": 0.2378,
      "step": 4360
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.15137894451618195,
      "learning_rate": 0.0002133364941750203,
      "loss": 0.2356,
      "step": 4365
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.22480323910713196,
      "learning_rate": 0.0002132348956922243,
      "loss": 0.247,
      "step": 4370
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.15436001121997833,
      "learning_rate": 0.0002131332972094283,
      "loss": 0.2536,
      "step": 4375
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1711360216140747,
      "learning_rate": 0.00021303169872663233,
      "loss": 0.2465,
      "step": 4380
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.16940416395664215,
      "learning_rate": 0.00021293010024383635,
      "loss": 0.2387,
      "step": 4385
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.17224819958209991,
      "learning_rate": 0.00021282850176104035,
      "loss": 0.2405,
      "step": 4390
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.17159898579120636,
      "learning_rate": 0.00021272690327824438,
      "loss": 0.2468,
      "step": 4395
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.17973218858242035,
      "learning_rate": 0.00021262530479544835,
      "loss": 0.2368,
      "step": 4400
    },
    {
      "epoch": 0.59,
      "eval_loss": 0.23201188445091248,
      "eval_runtime": 12.2989,
      "eval_samples_per_second": 8.131,
      "eval_steps_per_second": 1.057,
      "step": 4400
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.17559772729873657,
      "learning_rate": 0.00021252370631265238,
      "loss": 0.2266,
      "step": 4405
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.16006352007389069,
      "learning_rate": 0.00021242210782985638,
      "loss": 0.2436,
      "step": 4410
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1509973704814911,
      "learning_rate": 0.0002123205093470604,
      "loss": 0.2363,
      "step": 4415
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.1655089259147644,
      "learning_rate": 0.00021221891086426443,
      "loss": 0.234,
      "step": 4420
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1714477837085724,
      "learning_rate": 0.0002121173123814684,
      "loss": 0.2356,
      "step": 4425
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.15142808854579926,
      "learning_rate": 0.00021201571389867243,
      "loss": 0.2293,
      "step": 4430
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16409048438072205,
      "learning_rate": 0.00021191411541587643,
      "loss": 0.2395,
      "step": 4435
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16008780896663666,
      "learning_rate": 0.00021181251693308046,
      "loss": 0.2332,
      "step": 4440
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16187839210033417,
      "learning_rate": 0.00021171091845028449,
      "loss": 0.2464,
      "step": 4445
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16282960772514343,
      "learning_rate": 0.00021160931996748846,
      "loss": 0.2386,
      "step": 4450
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.15819750726222992,
      "learning_rate": 0.00021150772148469248,
      "loss": 0.2338,
      "step": 4455
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.16757479310035706,
      "learning_rate": 0.00021140612300189648,
      "loss": 0.2511,
      "step": 4460
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.22030451893806458,
      "learning_rate": 0.0002113045245191005,
      "loss": 0.245,
      "step": 4465
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.17077960073947906,
      "learning_rate": 0.0002112029260363045,
      "loss": 0.2453,
      "step": 4470
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.15714305639266968,
      "learning_rate": 0.0002111013275535085,
      "loss": 0.2351,
      "step": 4475
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.17575646936893463,
      "learning_rate": 0.0002109997290707125,
      "loss": 0.2431,
      "step": 4480
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1699962019920349,
      "learning_rate": 0.00021089813058791654,
      "loss": 0.2425,
      "step": 4485
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.1661881059408188,
      "learning_rate": 0.00021079653210512056,
      "loss": 0.241,
      "step": 4490
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.162850022315979,
      "learning_rate": 0.00021069493362232456,
      "loss": 0.2435,
      "step": 4495
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1492597907781601,
      "learning_rate": 0.00021059333513952856,
      "loss": 0.238,
      "step": 4500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.17611265182495117,
      "learning_rate": 0.00021049173665673256,
      "loss": 0.2394,
      "step": 4505
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.14539234340190887,
      "learning_rate": 0.0002103901381739366,
      "loss": 0.2293,
      "step": 4510
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.19685283303260803,
      "learning_rate": 0.0002102885396911406,
      "loss": 0.2491,
      "step": 4515
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.17888455092906952,
      "learning_rate": 0.00021018694120834462,
      "loss": 0.2452,
      "step": 4520
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.22511258721351624,
      "learning_rate": 0.0002100853427255486,
      "loss": 0.2397,
      "step": 4525
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.1670067459344864,
      "learning_rate": 0.00020998374424275262,
      "loss": 0.2516,
      "step": 4530
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.16582122445106506,
      "learning_rate": 0.00020988214575995664,
      "loss": 0.2462,
      "step": 4535
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.176377072930336,
      "learning_rate": 0.00020978054727716064,
      "loss": 0.2429,
      "step": 4540
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.17188894748687744,
      "learning_rate": 0.00020967894879436467,
      "loss": 0.2413,
      "step": 4545
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.17909131944179535,
      "learning_rate": 0.00020957735031156864,
      "loss": 0.2329,
      "step": 4550
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.16031379997730255,
      "learning_rate": 0.00020947575182877267,
      "loss": 0.24,
      "step": 4555
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.15776480734348297,
      "learning_rate": 0.00020937415334597667,
      "loss": 0.2379,
      "step": 4560
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.15474474430084229,
      "learning_rate": 0.0002092725548631807,
      "loss": 0.2292,
      "step": 4565
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.15582115948200226,
      "learning_rate": 0.00020917095638038472,
      "loss": 0.2354,
      "step": 4570
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1675635427236557,
      "learning_rate": 0.0002090693578975887,
      "loss": 0.2296,
      "step": 4575
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15805339813232422,
      "learning_rate": 0.00020896775941479272,
      "loss": 0.241,
      "step": 4580
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1845485121011734,
      "learning_rate": 0.00020886616093199672,
      "loss": 0.2379,
      "step": 4585
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.16028933227062225,
      "learning_rate": 0.00020876456244920075,
      "loss": 0.239,
      "step": 4590
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1496020257472992,
      "learning_rate": 0.00020866296396640475,
      "loss": 0.2334,
      "step": 4595
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.16687563061714172,
      "learning_rate": 0.00020856136548360875,
      "loss": 0.2422,
      "step": 4600
    },
    {
      "epoch": 0.62,
      "eval_loss": 0.22956176102161407,
      "eval_runtime": 12.3173,
      "eval_samples_per_second": 8.119,
      "eval_steps_per_second": 1.055,
      "step": 4600
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15467751026153564,
      "learning_rate": 0.00020845976700081275,
      "loss": 0.2389,
      "step": 4605
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15844061970710754,
      "learning_rate": 0.00020835816851801677,
      "loss": 0.2364,
      "step": 4610
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15389111638069153,
      "learning_rate": 0.0002082565700352208,
      "loss": 0.2437,
      "step": 4615
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.16043372452259064,
      "learning_rate": 0.0002081549715524248,
      "loss": 0.241,
      "step": 4620
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.16419793665409088,
      "learning_rate": 0.0002080533730696288,
      "loss": 0.2483,
      "step": 4625
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.17162354290485382,
      "learning_rate": 0.0002079517745868328,
      "loss": 0.2422,
      "step": 4630
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1643284112215042,
      "learning_rate": 0.00020785017610403683,
      "loss": 0.2401,
      "step": 4635
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15413311123847961,
      "learning_rate": 0.00020774857762124085,
      "loss": 0.2349,
      "step": 4640
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.15285798907279968,
      "learning_rate": 0.00020764697913844485,
      "loss": 0.2314,
      "step": 4645
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.16245749592781067,
      "learning_rate": 0.00020754538065564888,
      "loss": 0.2381,
      "step": 4650
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.15843135118484497,
      "learning_rate": 0.00020744378217285285,
      "loss": 0.2433,
      "step": 4655
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.15713627636432648,
      "learning_rate": 0.00020734218369005688,
      "loss": 0.228,
      "step": 4660
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.14795877039432526,
      "learning_rate": 0.00020724058520726088,
      "loss": 0.237,
      "step": 4665
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.19413219392299652,
      "learning_rate": 0.0002071389867244649,
      "loss": 0.2509,
      "step": 4670
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.15553881227970123,
      "learning_rate": 0.00020703738824166893,
      "loss": 0.2432,
      "step": 4675
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.160554438829422,
      "learning_rate": 0.0002069357897588729,
      "loss": 0.2335,
      "step": 4680
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.16348905861377716,
      "learning_rate": 0.00020683419127607693,
      "loss": 0.2359,
      "step": 4685
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1872895509004593,
      "learning_rate": 0.00020673259279328093,
      "loss": 0.2458,
      "step": 4690
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.16290859878063202,
      "learning_rate": 0.00020663099431048496,
      "loss": 0.236,
      "step": 4695
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.1568116992712021,
      "learning_rate": 0.00020652939582768896,
      "loss": 0.2423,
      "step": 4700
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.15578849613666534,
      "learning_rate": 0.00020642779734489296,
      "loss": 0.2411,
      "step": 4705
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.16723482310771942,
      "learning_rate": 0.00020632619886209696,
      "loss": 0.2454,
      "step": 4710
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.16843362152576447,
      "learning_rate": 0.00020622460037930099,
      "loss": 0.2472,
      "step": 4715
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.14999108016490936,
      "learning_rate": 0.000206123001896505,
      "loss": 0.2398,
      "step": 4720
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1615263968706131,
      "learning_rate": 0.000206021403413709,
      "loss": 0.2491,
      "step": 4725
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1606840342283249,
      "learning_rate": 0.000205919804930913,
      "loss": 0.2438,
      "step": 4730
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.16588029265403748,
      "learning_rate": 0.000205818206448117,
      "loss": 0.2338,
      "step": 4735
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.16583792865276337,
      "learning_rate": 0.00020571660796532104,
      "loss": 0.25,
      "step": 4740
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1552978754043579,
      "learning_rate": 0.00020561500948252504,
      "loss": 0.2263,
      "step": 4745
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.16447745263576508,
      "learning_rate": 0.00020551341099972906,
      "loss": 0.2336,
      "step": 4750
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.17926160991191864,
      "learning_rate": 0.00020541181251693304,
      "loss": 0.2405,
      "step": 4755
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.1564633697271347,
      "learning_rate": 0.00020531021403413706,
      "loss": 0.2398,
      "step": 4760
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.17044207453727722,
      "learning_rate": 0.0002052086155513411,
      "loss": 0.2285,
      "step": 4765
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.16121752560138702,
      "learning_rate": 0.0002051070170685451,
      "loss": 0.2351,
      "step": 4770
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.16189460456371307,
      "learning_rate": 0.00020500541858574912,
      "loss": 0.2388,
      "step": 4775
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15404239296913147,
      "learning_rate": 0.0002049038201029531,
      "loss": 0.2272,
      "step": 4780
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15855398774147034,
      "learning_rate": 0.00020480222162015712,
      "loss": 0.2457,
      "step": 4785
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.15893711149692535,
      "learning_rate": 0.00020470062313736114,
      "loss": 0.2426,
      "step": 4790
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.16226297616958618,
      "learning_rate": 0.00020459902465456514,
      "loss": 0.2376,
      "step": 4795
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.17168350517749786,
      "learning_rate": 0.00020449742617176917,
      "loss": 0.2229,
      "step": 4800
    },
    {
      "epoch": 0.65,
      "eval_loss": 0.23164094984531403,
      "eval_runtime": 12.3049,
      "eval_samples_per_second": 8.127,
      "eval_steps_per_second": 1.056,
      "step": 4800
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1533362865447998,
      "learning_rate": 0.00020439582768897314,
      "loss": 0.2338,
      "step": 4805
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.17153380811214447,
      "learning_rate": 0.00020429422920617717,
      "loss": 0.2467,
      "step": 4810
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.14446285367012024,
      "learning_rate": 0.00020419263072338117,
      "loss": 0.2431,
      "step": 4815
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.1592159867286682,
      "learning_rate": 0.0002040910322405852,
      "loss": 0.2343,
      "step": 4820
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.18703874945640564,
      "learning_rate": 0.00020398943375778922,
      "loss": 0.2441,
      "step": 4825
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.17335796356201172,
      "learning_rate": 0.0002038878352749932,
      "loss": 0.2484,
      "step": 4830
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.18010647594928741,
      "learning_rate": 0.00020378623679219722,
      "loss": 0.2418,
      "step": 4835
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.15310737490653992,
      "learning_rate": 0.00020368463830940122,
      "loss": 0.2406,
      "step": 4840
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.18068180978298187,
      "learning_rate": 0.00020358303982660525,
      "loss": 0.2296,
      "step": 4845
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.16593636572360992,
      "learning_rate": 0.00020348144134380925,
      "loss": 0.2358,
      "step": 4850
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.16543163359165192,
      "learning_rate": 0.00020337984286101325,
      "loss": 0.2413,
      "step": 4855
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.150202676653862,
      "learning_rate": 0.00020327824437821725,
      "loss": 0.2376,
      "step": 4860
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.14883151650428772,
      "learning_rate": 0.00020317664589542128,
      "loss": 0.2499,
      "step": 4865
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.17283891141414642,
      "learning_rate": 0.0002030750474126253,
      "loss": 0.2437,
      "step": 4870
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.18108980357646942,
      "learning_rate": 0.0002029734489298293,
      "loss": 0.231,
      "step": 4875
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.16342289745807648,
      "learning_rate": 0.0002028718504470333,
      "loss": 0.237,
      "step": 4880
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.16217459738254547,
      "learning_rate": 0.0002027702519642373,
      "loss": 0.2523,
      "step": 4885
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.1501469612121582,
      "learning_rate": 0.00020266865348144133,
      "loss": 0.2409,
      "step": 4890
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.16534055769443512,
      "learning_rate": 0.00020256705499864533,
      "loss": 0.2326,
      "step": 4895
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.14894132316112518,
      "learning_rate": 0.00020246545651584935,
      "loss": 0.2443,
      "step": 4900
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.16229505836963654,
      "learning_rate": 0.00020236385803305333,
      "loss": 0.2434,
      "step": 4905
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.15503187477588654,
      "learning_rate": 0.00020226225955025735,
      "loss": 0.244,
      "step": 4910
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.16498534381389618,
      "learning_rate": 0.00020216066106746138,
      "loss": 0.2572,
      "step": 4915
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.1462591141462326,
      "learning_rate": 0.00020205906258466538,
      "loss": 0.2435,
      "step": 4920
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.15089906752109528,
      "learning_rate": 0.0002019574641018694,
      "loss": 0.24,
      "step": 4925
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.15821728110313416,
      "learning_rate": 0.0002018558656190734,
      "loss": 0.234,
      "step": 4930
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.18016371130943298,
      "learning_rate": 0.0002017542671362774,
      "loss": 0.2457,
      "step": 4935
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.16402608156204224,
      "learning_rate": 0.0002016526686534814,
      "loss": 0.2351,
      "step": 4940
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1636524796485901,
      "learning_rate": 0.00020155107017068543,
      "loss": 0.2375,
      "step": 4945
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16903868317604065,
      "learning_rate": 0.00020144947168788946,
      "loss": 0.2346,
      "step": 4950
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.15321965515613556,
      "learning_rate": 0.00020134787320509346,
      "loss": 0.2383,
      "step": 4955
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1645309329032898,
      "learning_rate": 0.00020124627472229746,
      "loss": 0.2487,
      "step": 4960
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.162168949842453,
      "learning_rate": 0.00020114467623950146,
      "loss": 0.2369,
      "step": 4965
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16003426909446716,
      "learning_rate": 0.00020104307775670549,
      "loss": 0.2366,
      "step": 4970
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.1821078062057495,
      "learning_rate": 0.0002009414792739095,
      "loss": 0.2372,
      "step": 4975
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16169840097427368,
      "learning_rate": 0.0002008398807911135,
      "loss": 0.2425,
      "step": 4980
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16045285761356354,
      "learning_rate": 0.0002007382823083175,
      "loss": 0.2367,
      "step": 4985
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.16151385009288788,
      "learning_rate": 0.0002006366838255215,
      "loss": 0.2262,
      "step": 4990
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.17137840390205383,
      "learning_rate": 0.00020053508534272554,
      "loss": 0.24,
      "step": 4995
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.18344974517822266,
      "learning_rate": 0.00020043348685992954,
      "loss": 0.233,
      "step": 5000
    },
    {
      "epoch": 0.67,
      "eval_loss": 0.22942712903022766,
      "eval_runtime": 12.2853,
      "eval_samples_per_second": 8.14,
      "eval_steps_per_second": 1.058,
      "step": 5000
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.18056175112724304,
      "learning_rate": 0.00020033188837713357,
      "loss": 0.2338,
      "step": 5005
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.165287047624588,
      "learning_rate": 0.00020023028989433754,
      "loss": 0.237,
      "step": 5010
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.15869297087192535,
      "learning_rate": 0.00020012869141154156,
      "loss": 0.2434,
      "step": 5015
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1598794311285019,
      "learning_rate": 0.0002000270929287456,
      "loss": 0.2395,
      "step": 5020
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16903479397296906,
      "learning_rate": 0.0001999254944459496,
      "loss": 0.2512,
      "step": 5025
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1498563140630722,
      "learning_rate": 0.00019982389596315362,
      "loss": 0.2423,
      "step": 5030
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1890239417552948,
      "learning_rate": 0.0001997222974803576,
      "loss": 0.2397,
      "step": 5035
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16645453870296478,
      "learning_rate": 0.00019962069899756162,
      "loss": 0.2274,
      "step": 5040
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16793668270111084,
      "learning_rate": 0.00019951910051476562,
      "loss": 0.2316,
      "step": 5045
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14603449404239655,
      "learning_rate": 0.00019941750203196964,
      "loss": 0.257,
      "step": 5050
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.21400243043899536,
      "learning_rate": 0.00019931590354917367,
      "loss": 0.2395,
      "step": 5055
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.16512073576450348,
      "learning_rate": 0.00019921430506637764,
      "loss": 0.2461,
      "step": 5060
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.19040365517139435,
      "learning_rate": 0.00019911270658358167,
      "loss": 0.2362,
      "step": 5065
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1723097264766693,
      "learning_rate": 0.00019901110810078567,
      "loss": 0.2401,
      "step": 5070
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.1648743748664856,
      "learning_rate": 0.0001989095096179897,
      "loss": 0.2425,
      "step": 5075
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.14001113176345825,
      "learning_rate": 0.0001988079111351937,
      "loss": 0.2545,
      "step": 5080
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.15515771508216858,
      "learning_rate": 0.0001987063126523977,
      "loss": 0.2362,
      "step": 5085
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.17738980054855347,
      "learning_rate": 0.0001986047141696017,
      "loss": 0.235,
      "step": 5090
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1755344569683075,
      "learning_rate": 0.00019850311568680572,
      "loss": 0.2348,
      "step": 5095
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.16110146045684814,
      "learning_rate": 0.00019840151720400975,
      "loss": 0.2397,
      "step": 5100
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1504652500152588,
      "learning_rate": 0.00019829991872121375,
      "loss": 0.2267,
      "step": 5105
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15517444908618927,
      "learning_rate": 0.00019819832023841775,
      "loss": 0.2287,
      "step": 5110
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.17444974184036255,
      "learning_rate": 0.00019809672175562175,
      "loss": 0.2266,
      "step": 5115
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15939562022686005,
      "learning_rate": 0.00019799512327282578,
      "loss": 0.2456,
      "step": 5120
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.14747123420238495,
      "learning_rate": 0.0001978935247900298,
      "loss": 0.2358,
      "step": 5125
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15686067938804626,
      "learning_rate": 0.0001977919263072338,
      "loss": 0.2385,
      "step": 5130
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.16783802211284637,
      "learning_rate": 0.0001976903278244378,
      "loss": 0.2492,
      "step": 5135
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1649351716041565,
      "learning_rate": 0.0001975887293416418,
      "loss": 0.2388,
      "step": 5140
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.17191824316978455,
      "learning_rate": 0.00019748713085884583,
      "loss": 0.2351,
      "step": 5145
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15593518316745758,
      "learning_rate": 0.00019738553237604983,
      "loss": 0.236,
      "step": 5150
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15637411177158356,
      "learning_rate": 0.00019728393389325386,
      "loss": 0.2393,
      "step": 5155
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.18276983499526978,
      "learning_rate": 0.00019718233541045783,
      "loss": 0.2475,
      "step": 5160
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.15911991894245148,
      "learning_rate": 0.00019708073692766185,
      "loss": 0.2384,
      "step": 5165
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.16679738461971283,
      "learning_rate": 0.00019697913844486588,
      "loss": 0.2276,
      "step": 5170
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.14454111456871033,
      "learning_rate": 0.00019687753996206988,
      "loss": 0.2422,
      "step": 5175
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.16828599572181702,
      "learning_rate": 0.0001967759414792739,
      "loss": 0.2309,
      "step": 5180
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.1891907900571823,
      "learning_rate": 0.0001966743429964779,
      "loss": 0.2322,
      "step": 5185
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.17494632303714752,
      "learning_rate": 0.0001965727445136819,
      "loss": 0.246,
      "step": 5190
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.17786842584609985,
      "learning_rate": 0.0001964711460308859,
      "loss": 0.2298,
      "step": 5195
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.15944258868694305,
      "learning_rate": 0.00019636954754808993,
      "loss": 0.2409,
      "step": 5200
    },
    {
      "epoch": 0.7,
      "eval_loss": 0.22841547429561615,
      "eval_runtime": 12.3054,
      "eval_samples_per_second": 8.127,
      "eval_steps_per_second": 1.056,
      "step": 5200
    }
  ],
  "logging_steps": 5,
  "max_steps": 14864,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "total_flos": 6.759382486351872e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
