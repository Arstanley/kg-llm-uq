{
  "best_metric": 0.03157433867454529,
  "best_model_checkpoint": "/home/bo/Dropbox/Projects/kg-llm-uq/llamas/models/checkpoint-2400",
  "epoch": 1.11780630512619,
  "eval_steps": 200,
  "global_step": 2400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.379262775182724,
      "learning_rate": 1.4999999999999999e-05,
      "loss": 1.6062,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.47805559635162354,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 1.5422,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4924910366535187,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 1.5422,
      "step": 15
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5864177942276001,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 1.5575,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4403381943702698,
      "learning_rate": 7.5e-05,
      "loss": 1.4606,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7093654274940491,
      "learning_rate": 8.999999999999999e-05,
      "loss": 1.3049,
      "step": 30
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6152533888816833,
      "learning_rate": 0.00010499999999999999,
      "loss": 1.2751,
      "step": 35
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8349356651306152,
      "learning_rate": 0.00011999999999999999,
      "loss": 1.0942,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8565031290054321,
      "learning_rate": 0.000135,
      "loss": 0.9337,
      "step": 45
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5195858478546143,
      "learning_rate": 0.00015,
      "loss": 0.7887,
      "step": 50
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3621548116207123,
      "learning_rate": 0.000165,
      "loss": 0.7556,
      "step": 55
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3819538652896881,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.715,
      "step": 60
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3478069603443146,
      "learning_rate": 0.000195,
      "loss": 0.686,
      "step": 65
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3609238564968109,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.6914,
      "step": 70
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4019337296485901,
      "learning_rate": 0.000225,
      "loss": 0.6648,
      "step": 75
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3521921634674072,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.6288,
      "step": 80
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.37883830070495605,
      "learning_rate": 0.00025499999999999996,
      "loss": 0.6077,
      "step": 85
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4605925977230072,
      "learning_rate": 0.00027,
      "loss": 0.6033,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.49859127402305603,
      "learning_rate": 0.000285,
      "loss": 0.5607,
      "step": 95
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6291033029556274,
      "learning_rate": 0.0003,
      "loss": 0.5633,
      "step": 100
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6059991717338562,
      "learning_rate": 0.0002996423462088698,
      "loss": 0.5244,
      "step": 105
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7340793609619141,
      "learning_rate": 0.0002992846924177396,
      "loss": 0.5342,
      "step": 110
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5314730405807495,
      "learning_rate": 0.0002989270386266094,
      "loss": 0.508,
      "step": 115
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6257819533348083,
      "learning_rate": 0.00029856938483547923,
      "loss": 0.4754,
      "step": 120
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6857722401618958,
      "learning_rate": 0.000298211731044349,
      "loss": 0.4866,
      "step": 125
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8252089023590088,
      "learning_rate": 0.00029785407725321886,
      "loss": 0.4505,
      "step": 130
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6716639995574951,
      "learning_rate": 0.0002974964234620887,
      "loss": 0.4458,
      "step": 135
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7996184825897217,
      "learning_rate": 0.0002971387696709585,
      "loss": 0.4247,
      "step": 140
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7249406576156616,
      "learning_rate": 0.0002967811158798283,
      "loss": 0.3978,
      "step": 145
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6708111763000488,
      "learning_rate": 0.0002964234620886981,
      "loss": 0.4135,
      "step": 150
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6448484063148499,
      "learning_rate": 0.0002960658082975679,
      "loss": 0.3921,
      "step": 155
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5611176490783691,
      "learning_rate": 0.00029570815450643775,
      "loss": 0.3598,
      "step": 160
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6137551665306091,
      "learning_rate": 0.0002953505007153076,
      "loss": 0.3423,
      "step": 165
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9189370274543762,
      "learning_rate": 0.0002949928469241774,
      "loss": 0.3941,
      "step": 170
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5988947749137878,
      "learning_rate": 0.00029463519313304717,
      "loss": 0.3673,
      "step": 175
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6418901085853577,
      "learning_rate": 0.000294277539341917,
      "loss": 0.3359,
      "step": 180
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0691173076629639,
      "learning_rate": 0.0002939198855507868,
      "loss": 0.3546,
      "step": 185
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6389315128326416,
      "learning_rate": 0.00029356223175965664,
      "loss": 0.3533,
      "step": 190
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7112616300582886,
      "learning_rate": 0.0002932045779685265,
      "loss": 0.328,
      "step": 195
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.077401876449585,
      "learning_rate": 0.00029284692417739627,
      "loss": 0.3159,
      "step": 200
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.30109816789627075,
      "eval_runtime": 6.2864,
      "eval_samples_per_second": 15.907,
      "eval_steps_per_second": 2.068,
      "step": 200
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9521806240081787,
      "learning_rate": 0.00029248927038626605,
      "loss": 0.2595,
      "step": 205
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8900402188301086,
      "learning_rate": 0.0002921316165951359,
      "loss": 0.3218,
      "step": 210
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6118184328079224,
      "learning_rate": 0.0002917739628040057,
      "loss": 0.2818,
      "step": 215
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7396877408027649,
      "learning_rate": 0.0002914163090128755,
      "loss": 0.2722,
      "step": 220
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.155815839767456,
      "learning_rate": 0.0002910586552217453,
      "loss": 0.2647,
      "step": 225
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.794549286365509,
      "learning_rate": 0.00029070100143061516,
      "loss": 0.2196,
      "step": 230
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.2496204376220703,
      "learning_rate": 0.00029034334763948494,
      "loss": 0.2486,
      "step": 235
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7176342010498047,
      "learning_rate": 0.0002899856938483548,
      "loss": 0.2311,
      "step": 240
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6528435945510864,
      "learning_rate": 0.00028962804005722457,
      "loss": 0.2454,
      "step": 245
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6767492890357971,
      "learning_rate": 0.0002892703862660944,
      "loss": 0.2316,
      "step": 250
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9650689363479614,
      "learning_rate": 0.0002889127324749642,
      "loss": 0.254,
      "step": 255
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7315481305122375,
      "learning_rate": 0.00028855507868383404,
      "loss": 0.2207,
      "step": 260
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6443731188774109,
      "learning_rate": 0.00028819742489270383,
      "loss": 0.2201,
      "step": 265
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.866019606590271,
      "learning_rate": 0.0002878397711015736,
      "loss": 0.2301,
      "step": 270
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7839658260345459,
      "learning_rate": 0.00028748211731044346,
      "loss": 0.215,
      "step": 275
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7717844843864441,
      "learning_rate": 0.0002871244635193133,
      "loss": 0.1927,
      "step": 280
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5572271943092346,
      "learning_rate": 0.0002867668097281831,
      "loss": 0.2026,
      "step": 285
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6704198122024536,
      "learning_rate": 0.0002864091559370529,
      "loss": 0.2252,
      "step": 290
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1609948873519897,
      "learning_rate": 0.0002860515021459227,
      "loss": 0.1968,
      "step": 295
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8245071172714233,
      "learning_rate": 0.0002856938483547925,
      "loss": 0.1912,
      "step": 300
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6764411330223083,
      "learning_rate": 0.00028533619456366235,
      "loss": 0.2141,
      "step": 305
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7324936389923096,
      "learning_rate": 0.0002849785407725322,
      "loss": 0.2039,
      "step": 310
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6095176339149475,
      "learning_rate": 0.000284620886981402,
      "loss": 0.2006,
      "step": 315
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7220770716667175,
      "learning_rate": 0.00028426323319027177,
      "loss": 0.1583,
      "step": 320
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6633134484291077,
      "learning_rate": 0.0002839055793991416,
      "loss": 0.1779,
      "step": 325
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6472673416137695,
      "learning_rate": 0.0002835479256080114,
      "loss": 0.1846,
      "step": 330
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6230971217155457,
      "learning_rate": 0.00028319027181688124,
      "loss": 0.1401,
      "step": 335
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5709161758422852,
      "learning_rate": 0.0002828326180257511,
      "loss": 0.1624,
      "step": 340
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4405706226825714,
      "learning_rate": 0.00028247496423462087,
      "loss": 0.1642,
      "step": 345
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6257874369621277,
      "learning_rate": 0.00028211731044349065,
      "loss": 0.1827,
      "step": 350
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4758528172969818,
      "learning_rate": 0.0002817596566523605,
      "loss": 0.1485,
      "step": 355
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.547324001789093,
      "learning_rate": 0.0002814020028612303,
      "loss": 0.1455,
      "step": 360
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4624596834182739,
      "learning_rate": 0.0002810443490701001,
      "loss": 0.1363,
      "step": 365
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6847907900810242,
      "learning_rate": 0.00028068669527896997,
      "loss": 0.1807,
      "step": 370
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5878551602363586,
      "learning_rate": 0.00028032904148783975,
      "loss": 0.1275,
      "step": 375
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5270897150039673,
      "learning_rate": 0.00027997138769670954,
      "loss": 0.1524,
      "step": 380
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.530502438545227,
      "learning_rate": 0.0002796137339055794,
      "loss": 0.1359,
      "step": 385
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6701236367225647,
      "learning_rate": 0.00027925608011444917,
      "loss": 0.1543,
      "step": 390
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5156545042991638,
      "learning_rate": 0.000278898426323319,
      "loss": 0.1481,
      "step": 395
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6706433892250061,
      "learning_rate": 0.00027854077253218885,
      "loss": 0.1559,
      "step": 400
    },
    {
      "epoch": 0.19,
      "eval_loss": 0.13624189794063568,
      "eval_runtime": 6.0998,
      "eval_samples_per_second": 16.394,
      "eval_steps_per_second": 2.131,
      "step": 400
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6843015551567078,
      "learning_rate": 0.00027818311874105864,
      "loss": 0.1849,
      "step": 405
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.48232847452163696,
      "learning_rate": 0.00027782546494992843,
      "loss": 0.1072,
      "step": 410
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5118234157562256,
      "learning_rate": 0.00027746781115879827,
      "loss": 0.1699,
      "step": 415
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.48224249482154846,
      "learning_rate": 0.00027711015736766806,
      "loss": 0.1393,
      "step": 420
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4874871075153351,
      "learning_rate": 0.0002767525035765379,
      "loss": 0.1374,
      "step": 425
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5094722509384155,
      "learning_rate": 0.0002763948497854077,
      "loss": 0.1482,
      "step": 430
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5647515058517456,
      "learning_rate": 0.00027603719599427753,
      "loss": 0.1438,
      "step": 435
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.46288231015205383,
      "learning_rate": 0.0002756795422031473,
      "loss": 0.1098,
      "step": 440
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4923100173473358,
      "learning_rate": 0.00027532188841201716,
      "loss": 0.131,
      "step": 445
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3754996359348297,
      "learning_rate": 0.00027496423462088695,
      "loss": 0.1276,
      "step": 450
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.42809775471687317,
      "learning_rate": 0.0002746065808297568,
      "loss": 0.1208,
      "step": 455
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5552361607551575,
      "learning_rate": 0.0002742489270386266,
      "loss": 0.1647,
      "step": 460
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6432417631149292,
      "learning_rate": 0.00027389127324749636,
      "loss": 0.1426,
      "step": 465
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5092611908912659,
      "learning_rate": 0.0002735336194563662,
      "loss": 0.1351,
      "step": 470
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4470369815826416,
      "learning_rate": 0.00027317596566523605,
      "loss": 0.1079,
      "step": 475
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5907160639762878,
      "learning_rate": 0.00027281831187410583,
      "loss": 0.1491,
      "step": 480
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5297710299491882,
      "learning_rate": 0.0002724606580829757,
      "loss": 0.127,
      "step": 485
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4238237142562866,
      "learning_rate": 0.00027210300429184546,
      "loss": 0.1043,
      "step": 490
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.36685457825660706,
      "learning_rate": 0.00027174535050071525,
      "loss": 0.146,
      "step": 495
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.32640427350997925,
      "learning_rate": 0.0002713876967095851,
      "loss": 0.135,
      "step": 500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5416951179504395,
      "learning_rate": 0.00027103004291845494,
      "loss": 0.1063,
      "step": 505
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5536446571350098,
      "learning_rate": 0.0002706723891273247,
      "loss": 0.1522,
      "step": 510
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5701792240142822,
      "learning_rate": 0.00027031473533619456,
      "loss": 0.1114,
      "step": 515
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.49262961745262146,
      "learning_rate": 0.00026995708154506435,
      "loss": 0.1155,
      "step": 520
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6054053902626038,
      "learning_rate": 0.00026959942775393414,
      "loss": 0.1204,
      "step": 525
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5569124817848206,
      "learning_rate": 0.000269241773962804,
      "loss": 0.1253,
      "step": 530
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.34597891569137573,
      "learning_rate": 0.0002688841201716738,
      "loss": 0.1361,
      "step": 535
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5758796334266663,
      "learning_rate": 0.0002685264663805436,
      "loss": 0.1256,
      "step": 540
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.43532794713974,
      "learning_rate": 0.00026816881258941345,
      "loss": 0.1203,
      "step": 545
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.48018935322761536,
      "learning_rate": 0.00026781115879828324,
      "loss": 0.1075,
      "step": 550
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6209208369255066,
      "learning_rate": 0.00026745350500715303,
      "loss": 0.1307,
      "step": 555
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5131470561027527,
      "learning_rate": 0.00026709585121602287,
      "loss": 0.1316,
      "step": 560
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.467910498380661,
      "learning_rate": 0.0002667381974248927,
      "loss": 0.1027,
      "step": 565
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.49111446738243103,
      "learning_rate": 0.0002663805436337625,
      "loss": 0.0843,
      "step": 570
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4730786681175232,
      "learning_rate": 0.00026602288984263234,
      "loss": 0.1067,
      "step": 575
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.44606903195381165,
      "learning_rate": 0.00026566523605150213,
      "loss": 0.1398,
      "step": 580
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.44434136152267456,
      "learning_rate": 0.0002653075822603719,
      "loss": 0.1337,
      "step": 585
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6871078014373779,
      "learning_rate": 0.00026494992846924176,
      "loss": 0.1105,
      "step": 590
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4746786952018738,
      "learning_rate": 0.00026459227467811154,
      "loss": 0.1357,
      "step": 595
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3526788651943207,
      "learning_rate": 0.0002642346208869814,
      "loss": 0.086,
      "step": 600
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.1103004515171051,
      "eval_runtime": 6.1009,
      "eval_samples_per_second": 16.391,
      "eval_steps_per_second": 2.131,
      "step": 600
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6901889443397522,
      "learning_rate": 0.0002638769670958512,
      "loss": 0.1162,
      "step": 605
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.34441515803337097,
      "learning_rate": 0.000263519313304721,
      "loss": 0.1121,
      "step": 610
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4725894629955292,
      "learning_rate": 0.0002631616595135908,
      "loss": 0.119,
      "step": 615
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.32832539081573486,
      "learning_rate": 0.00026280400572246065,
      "loss": 0.1128,
      "step": 620
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6399173140525818,
      "learning_rate": 0.00026244635193133043,
      "loss": 0.1375,
      "step": 625
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.42610323429107666,
      "learning_rate": 0.0002620886981402003,
      "loss": 0.1078,
      "step": 630
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4896005392074585,
      "learning_rate": 0.00026173104434907006,
      "loss": 0.1038,
      "step": 635
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.472851425409317,
      "learning_rate": 0.00026137339055793985,
      "loss": 0.1013,
      "step": 640
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.27530714869499207,
      "learning_rate": 0.0002610157367668097,
      "loss": 0.1215,
      "step": 645
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.49096694588661194,
      "learning_rate": 0.00026065808297567953,
      "loss": 0.1528,
      "step": 650
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6109957098960876,
      "learning_rate": 0.0002603004291845493,
      "loss": 0.11,
      "step": 655
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.30811557173728943,
      "learning_rate": 0.00025994277539341916,
      "loss": 0.1258,
      "step": 660
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5634673237800598,
      "learning_rate": 0.00025958512160228895,
      "loss": 0.1111,
      "step": 665
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7396148443222046,
      "learning_rate": 0.00025922746781115874,
      "loss": 0.0838,
      "step": 670
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.45446696877479553,
      "learning_rate": 0.0002588698140200286,
      "loss": 0.1092,
      "step": 675
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4911167621612549,
      "learning_rate": 0.0002585121602288984,
      "loss": 0.0964,
      "step": 680
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3618662655353546,
      "learning_rate": 0.0002581545064377682,
      "loss": 0.0964,
      "step": 685
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4192012846469879,
      "learning_rate": 0.00025779685264663805,
      "loss": 0.0927,
      "step": 690
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6268917918205261,
      "learning_rate": 0.00025743919885550784,
      "loss": 0.0999,
      "step": 695
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.49908626079559326,
      "learning_rate": 0.0002570815450643776,
      "loss": 0.0948,
      "step": 700
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6230370998382568,
      "learning_rate": 0.00025672389127324747,
      "loss": 0.0909,
      "step": 705
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.4852205216884613,
      "learning_rate": 0.0002563662374821173,
      "loss": 0.1026,
      "step": 710
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.39765480160713196,
      "learning_rate": 0.0002560085836909871,
      "loss": 0.0874,
      "step": 715
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.55474853515625,
      "learning_rate": 0.00025565092989985694,
      "loss": 0.0887,
      "step": 720
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5864394307136536,
      "learning_rate": 0.0002552932761087267,
      "loss": 0.0833,
      "step": 725
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.35622668266296387,
      "learning_rate": 0.0002549356223175965,
      "loss": 0.091,
      "step": 730
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5017713308334351,
      "learning_rate": 0.00025457796852646636,
      "loss": 0.1044,
      "step": 735
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3729548454284668,
      "learning_rate": 0.0002542203147353362,
      "loss": 0.1074,
      "step": 740
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5153675675392151,
      "learning_rate": 0.000253862660944206,
      "loss": 0.1058,
      "step": 745
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4382741451263428,
      "learning_rate": 0.0002535050071530758,
      "loss": 0.1212,
      "step": 750
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5136945247650146,
      "learning_rate": 0.0002531473533619456,
      "loss": 0.1032,
      "step": 755
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6090183854103088,
      "learning_rate": 0.0002527896995708154,
      "loss": 0.09,
      "step": 760
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3165133595466614,
      "learning_rate": 0.00025243204577968524,
      "loss": 0.0808,
      "step": 765
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.47972220182418823,
      "learning_rate": 0.0002520743919885551,
      "loss": 0.1141,
      "step": 770
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3993671238422394,
      "learning_rate": 0.0002517167381974249,
      "loss": 0.0798,
      "step": 775
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5643846988677979,
      "learning_rate": 0.00025135908440629466,
      "loss": 0.0979,
      "step": 780
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.337849497795105,
      "learning_rate": 0.0002510014306151645,
      "loss": 0.0816,
      "step": 785
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.28069475293159485,
      "learning_rate": 0.0002506437768240343,
      "loss": 0.0851,
      "step": 790
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.39433753490448,
      "learning_rate": 0.00025028612303290413,
      "loss": 0.1302,
      "step": 795
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6063970327377319,
      "learning_rate": 0.000249928469241774,
      "loss": 0.0965,
      "step": 800
    },
    {
      "epoch": 0.37,
      "eval_loss": 0.07553515583276749,
      "eval_runtime": 6.101,
      "eval_samples_per_second": 16.391,
      "eval_steps_per_second": 2.131,
      "step": 800
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.417673796415329,
      "learning_rate": 0.00024957081545064376,
      "loss": 0.0807,
      "step": 805
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.32246387004852295,
      "learning_rate": 0.00024921316165951355,
      "loss": 0.0726,
      "step": 810
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.48414674401283264,
      "learning_rate": 0.0002488555078683834,
      "loss": 0.0913,
      "step": 815
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.44579586386680603,
      "learning_rate": 0.0002484978540772532,
      "loss": 0.0998,
      "step": 820
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.23227879405021667,
      "learning_rate": 0.000248140200286123,
      "loss": 0.0973,
      "step": 825
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3057343661785126,
      "learning_rate": 0.00024778254649499286,
      "loss": 0.0735,
      "step": 830
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.4732973575592041,
      "learning_rate": 0.00024742489270386265,
      "loss": 0.0858,
      "step": 835
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3048236072063446,
      "learning_rate": 0.00024706723891273244,
      "loss": 0.0917,
      "step": 840
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3092619776725769,
      "learning_rate": 0.0002467095851216023,
      "loss": 0.0654,
      "step": 845
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.22660000622272491,
      "learning_rate": 0.00024635193133047207,
      "loss": 0.0885,
      "step": 850
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.27233877778053284,
      "learning_rate": 0.0002459942775393419,
      "loss": 0.0887,
      "step": 855
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6003687381744385,
      "learning_rate": 0.00024563662374821175,
      "loss": 0.1224,
      "step": 860
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5492870807647705,
      "learning_rate": 0.00024527896995708154,
      "loss": 0.0977,
      "step": 865
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5172010064125061,
      "learning_rate": 0.0002449213161659513,
      "loss": 0.111,
      "step": 870
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5315970778465271,
      "learning_rate": 0.00024456366237482117,
      "loss": 0.11,
      "step": 875
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.46920162439346313,
      "learning_rate": 0.00024420600858369095,
      "loss": 0.0957,
      "step": 880
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9000978469848633,
      "learning_rate": 0.0002438483547925608,
      "loss": 0.0924,
      "step": 885
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.42253577709198,
      "learning_rate": 0.0002434907010014306,
      "loss": 0.0998,
      "step": 890
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6860753893852234,
      "learning_rate": 0.0002431330472103004,
      "loss": 0.0838,
      "step": 895
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.44288700819015503,
      "learning_rate": 0.00024277539341917024,
      "loss": 0.0877,
      "step": 900
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5012921094894409,
      "learning_rate": 0.00024241773962804003,
      "loss": 0.0912,
      "step": 905
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5003051161766052,
      "learning_rate": 0.00024206008583690984,
      "loss": 0.0806,
      "step": 910
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.37244123220443726,
      "learning_rate": 0.00024170243204577968,
      "loss": 0.0736,
      "step": 915
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.45806941390037537,
      "learning_rate": 0.00024134477825464947,
      "loss": 0.0775,
      "step": 920
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.43767112493515015,
      "learning_rate": 0.00024098712446351929,
      "loss": 0.0802,
      "step": 925
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.36565670371055603,
      "learning_rate": 0.0002406294706723891,
      "loss": 0.1052,
      "step": 930
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.2933093309402466,
      "learning_rate": 0.00024027181688125892,
      "loss": 0.0841,
      "step": 935
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.37429434061050415,
      "learning_rate": 0.00023991416309012873,
      "loss": 0.0728,
      "step": 940
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5871070027351379,
      "learning_rate": 0.00023955650929899854,
      "loss": 0.0883,
      "step": 945
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.32863494753837585,
      "learning_rate": 0.00023919885550786836,
      "loss": 0.0747,
      "step": 950
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3852473497390747,
      "learning_rate": 0.00023884120171673817,
      "loss": 0.0981,
      "step": 955
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.37789225578308105,
      "learning_rate": 0.000238483547925608,
      "loss": 0.0883,
      "step": 960
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.20560096204280853,
      "learning_rate": 0.0002381258941344778,
      "loss": 0.0734,
      "step": 965
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.48182442784309387,
      "learning_rate": 0.00023776824034334762,
      "loss": 0.0877,
      "step": 970
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.36547771096229553,
      "learning_rate": 0.00023741058655221743,
      "loss": 0.0649,
      "step": 975
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3339424133300781,
      "learning_rate": 0.00023705293276108722,
      "loss": 0.0734,
      "step": 980
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5364779233932495,
      "learning_rate": 0.00023669527896995706,
      "loss": 0.0887,
      "step": 985
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.4442126750946045,
      "learning_rate": 0.00023633762517882688,
      "loss": 0.0818,
      "step": 990
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3467923402786255,
      "learning_rate": 0.00023597997138769666,
      "loss": 0.0965,
      "step": 995
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4124046266078949,
      "learning_rate": 0.0002356223175965665,
      "loss": 0.0868,
      "step": 1000
    },
    {
      "epoch": 0.47,
      "eval_loss": 0.05644877254962921,
      "eval_runtime": 6.1004,
      "eval_samples_per_second": 16.392,
      "eval_steps_per_second": 2.131,
      "step": 1000
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.39816075563430786,
      "learning_rate": 0.00023526466380543632,
      "loss": 0.0783,
      "step": 1005
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5127551555633545,
      "learning_rate": 0.0002349070100143061,
      "loss": 0.0704,
      "step": 1010
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.4221580922603607,
      "learning_rate": 0.00023454935622317595,
      "loss": 0.0632,
      "step": 1015
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.37732943892478943,
      "learning_rate": 0.00023419170243204576,
      "loss": 0.098,
      "step": 1020
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.39290544390678406,
      "learning_rate": 0.00023383404864091555,
      "loss": 0.0739,
      "step": 1025
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2595028281211853,
      "learning_rate": 0.0002334763948497854,
      "loss": 0.0736,
      "step": 1030
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.4465737044811249,
      "learning_rate": 0.0002331187410586552,
      "loss": 0.0733,
      "step": 1035
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.44362005591392517,
      "learning_rate": 0.000232761087267525,
      "loss": 0.0764,
      "step": 1040
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.3549788296222687,
      "learning_rate": 0.00023240343347639484,
      "loss": 0.0756,
      "step": 1045
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5763105750083923,
      "learning_rate": 0.00023204577968526465,
      "loss": 0.0828,
      "step": 1050
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.27785757184028625,
      "learning_rate": 0.00023168812589413444,
      "loss": 0.0998,
      "step": 1055
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.436402827501297,
      "learning_rate": 0.00023133047210300428,
      "loss": 0.0761,
      "step": 1060
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4008409082889557,
      "learning_rate": 0.0002309728183118741,
      "loss": 0.0885,
      "step": 1065
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.312709778547287,
      "learning_rate": 0.00023061516452074388,
      "loss": 0.0991,
      "step": 1070
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3503429591655731,
      "learning_rate": 0.00023025751072961373,
      "loss": 0.0839,
      "step": 1075
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.34124964475631714,
      "learning_rate": 0.00022989985693848354,
      "loss": 0.074,
      "step": 1080
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.4347098469734192,
      "learning_rate": 0.00022954220314735333,
      "loss": 0.0828,
      "step": 1085
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3242586851119995,
      "learning_rate": 0.00022918454935622317,
      "loss": 0.0876,
      "step": 1090
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.48615792393684387,
      "learning_rate": 0.00022882689556509298,
      "loss": 0.0862,
      "step": 1095
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.31206953525543213,
      "learning_rate": 0.00022846924177396277,
      "loss": 0.0941,
      "step": 1100
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5395301580429077,
      "learning_rate": 0.0002281115879828326,
      "loss": 0.0693,
      "step": 1105
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.506336510181427,
      "learning_rate": 0.00022775393419170243,
      "loss": 0.0565,
      "step": 1110
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5333818197250366,
      "learning_rate": 0.00022739628040057222,
      "loss": 0.0724,
      "step": 1115
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4728677272796631,
      "learning_rate": 0.00022703862660944203,
      "loss": 0.082,
      "step": 1120
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.37162280082702637,
      "learning_rate": 0.00022668097281831187,
      "loss": 0.0644,
      "step": 1125
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3906702399253845,
      "learning_rate": 0.00022632331902718166,
      "loss": 0.1079,
      "step": 1130
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3988654613494873,
      "learning_rate": 0.00022596566523605148,
      "loss": 0.0655,
      "step": 1135
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.33606529235839844,
      "learning_rate": 0.00022560801144492132,
      "loss": 0.0605,
      "step": 1140
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.31643199920654297,
      "learning_rate": 0.0002252503576537911,
      "loss": 0.0636,
      "step": 1145
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.36754387617111206,
      "learning_rate": 0.00022489270386266092,
      "loss": 0.0713,
      "step": 1150
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5767832398414612,
      "learning_rate": 0.00022453505007153076,
      "loss": 0.0738,
      "step": 1155
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5257533192634583,
      "learning_rate": 0.00022417739628040055,
      "loss": 0.0902,
      "step": 1160
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.34906721115112305,
      "learning_rate": 0.00022381974248927036,
      "loss": 0.0625,
      "step": 1165
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.41432470083236694,
      "learning_rate": 0.0002234620886981402,
      "loss": 0.0692,
      "step": 1170
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.32147645950317383,
      "learning_rate": 0.00022310443490701,
      "loss": 0.0684,
      "step": 1175
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.2062252312898636,
      "learning_rate": 0.0002227467811158798,
      "loss": 0.059,
      "step": 1180
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.4260958731174469,
      "learning_rate": 0.00022238912732474965,
      "loss": 0.068,
      "step": 1185
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.24583712220191956,
      "learning_rate": 0.00022203147353361944,
      "loss": 0.0681,
      "step": 1190
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.391618937253952,
      "learning_rate": 0.00022167381974248925,
      "loss": 0.0728,
      "step": 1195
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3514546751976013,
      "learning_rate": 0.0002213161659513591,
      "loss": 0.0624,
      "step": 1200
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.04638045281171799,
      "eval_runtime": 6.1011,
      "eval_samples_per_second": 16.39,
      "eval_steps_per_second": 2.131,
      "step": 1200
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.351471483707428,
      "learning_rate": 0.00022095851216022888,
      "loss": 0.0584,
      "step": 1205
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.38989919424057007,
      "learning_rate": 0.0002206008583690987,
      "loss": 0.0671,
      "step": 1210
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.2583673894405365,
      "learning_rate": 0.00022024320457796848,
      "loss": 0.0686,
      "step": 1215
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.26407021284103394,
      "learning_rate": 0.00021988555078683832,
      "loss": 0.0632,
      "step": 1220
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.33293941617012024,
      "learning_rate": 0.00021952789699570814,
      "loss": 0.083,
      "step": 1225
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6525919437408447,
      "learning_rate": 0.00021917024320457793,
      "loss": 0.0604,
      "step": 1230
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3726056218147278,
      "learning_rate": 0.00021881258941344777,
      "loss": 0.0699,
      "step": 1235
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.37452250719070435,
      "learning_rate": 0.00021845493562231758,
      "loss": 0.062,
      "step": 1240
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.4599311649799347,
      "learning_rate": 0.00021809728183118737,
      "loss": 0.0736,
      "step": 1245
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.34571465849876404,
      "learning_rate": 0.0002177396280400572,
      "loss": 0.0605,
      "step": 1250
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.42411598563194275,
      "learning_rate": 0.00021738197424892703,
      "loss": 0.06,
      "step": 1255
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3928501009941101,
      "learning_rate": 0.00021702432045779681,
      "loss": 0.0854,
      "step": 1260
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.34391066431999207,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.0639,
      "step": 1265
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3456075191497803,
      "learning_rate": 0.00021630901287553647,
      "loss": 0.0503,
      "step": 1270
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.336885005235672,
      "learning_rate": 0.00021595135908440626,
      "loss": 0.0722,
      "step": 1275
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.27508965134620667,
      "learning_rate": 0.00021559370529327607,
      "loss": 0.07,
      "step": 1280
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.2825224697589874,
      "learning_rate": 0.00021523605150214592,
      "loss": 0.0541,
      "step": 1285
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.23743975162506104,
      "learning_rate": 0.0002148783977110157,
      "loss": 0.065,
      "step": 1290
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3976512849330902,
      "learning_rate": 0.00021452074391988552,
      "loss": 0.048,
      "step": 1295
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.40067213773727417,
      "learning_rate": 0.00021416309012875536,
      "loss": 0.0651,
      "step": 1300
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.272854208946228,
      "learning_rate": 0.00021380543633762515,
      "loss": 0.0747,
      "step": 1305
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.31727197766304016,
      "learning_rate": 0.00021344778254649496,
      "loss": 0.0637,
      "step": 1310
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3305126130580902,
      "learning_rate": 0.0002130901287553648,
      "loss": 0.0683,
      "step": 1315
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.20349398255348206,
      "learning_rate": 0.0002127324749642346,
      "loss": 0.0546,
      "step": 1320
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.2648598551750183,
      "learning_rate": 0.0002123748211731044,
      "loss": 0.0628,
      "step": 1325
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.31578347086906433,
      "learning_rate": 0.00021201716738197425,
      "loss": 0.0677,
      "step": 1330
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.35016873478889465,
      "learning_rate": 0.00021165951359084404,
      "loss": 0.0708,
      "step": 1335
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.32113006711006165,
      "learning_rate": 0.00021130185979971385,
      "loss": 0.0763,
      "step": 1340
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1347259283065796,
      "learning_rate": 0.0002109442060085837,
      "loss": 0.0801,
      "step": 1345
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4960762858390808,
      "learning_rate": 0.00021058655221745348,
      "loss": 0.066,
      "step": 1350
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5061559677124023,
      "learning_rate": 0.0002102288984263233,
      "loss": 0.0859,
      "step": 1355
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.36622634530067444,
      "learning_rate": 0.00020987124463519314,
      "loss": 0.068,
      "step": 1360
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.43622785806655884,
      "learning_rate": 0.00020951359084406292,
      "loss": 0.0577,
      "step": 1365
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.325064092874527,
      "learning_rate": 0.00020915593705293274,
      "loss": 0.0613,
      "step": 1370
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.31351321935653687,
      "learning_rate": 0.00020879828326180258,
      "loss": 0.0658,
      "step": 1375
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.3499143421649933,
      "learning_rate": 0.00020844062947067237,
      "loss": 0.0716,
      "step": 1380
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.39258667826652527,
      "learning_rate": 0.00020808297567954218,
      "loss": 0.0643,
      "step": 1385
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5344862341880798,
      "learning_rate": 0.00020772532188841202,
      "loss": 0.0674,
      "step": 1390
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.2565006613731384,
      "learning_rate": 0.0002073676680972818,
      "loss": 0.0677,
      "step": 1395
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.24505725502967834,
      "learning_rate": 0.00020701001430615163,
      "loss": 0.0671,
      "step": 1400
    },
    {
      "epoch": 0.65,
      "eval_loss": 0.044199757277965546,
      "eval_runtime": 6.0999,
      "eval_samples_per_second": 16.394,
      "eval_steps_per_second": 2.131,
      "step": 1400
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.271374374628067,
      "learning_rate": 0.00020665236051502144,
      "loss": 0.0643,
      "step": 1405
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.34781521558761597,
      "learning_rate": 0.00020629470672389126,
      "loss": 0.0722,
      "step": 1410
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.25837087631225586,
      "learning_rate": 0.00020593705293276107,
      "loss": 0.0557,
      "step": 1415
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.18311218917369843,
      "learning_rate": 0.00020557939914163088,
      "loss": 0.0555,
      "step": 1420
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.44915419816970825,
      "learning_rate": 0.0002052217453505007,
      "loss": 0.0661,
      "step": 1425
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.2641124427318573,
      "learning_rate": 0.00020486409155937051,
      "loss": 0.0503,
      "step": 1430
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3905640244483948,
      "learning_rate": 0.00020450643776824033,
      "loss": 0.0858,
      "step": 1435
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.38894402980804443,
      "learning_rate": 0.00020414878397711014,
      "loss": 0.063,
      "step": 1440
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.42507246136665344,
      "learning_rate": 0.00020379113018597996,
      "loss": 0.0595,
      "step": 1445
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.2600724399089813,
      "learning_rate": 0.00020343347639484977,
      "loss": 0.0728,
      "step": 1450
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.2840134799480438,
      "learning_rate": 0.00020307582260371956,
      "loss": 0.0631,
      "step": 1455
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.4687870144844055,
      "learning_rate": 0.0002027181688125894,
      "loss": 0.0566,
      "step": 1460
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3259858787059784,
      "learning_rate": 0.00020236051502145922,
      "loss": 0.0583,
      "step": 1465
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.2983416020870209,
      "learning_rate": 0.000202002861230329,
      "loss": 0.0498,
      "step": 1470
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.32253021001815796,
      "learning_rate": 0.00020164520743919885,
      "loss": 0.048,
      "step": 1475
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.20426638424396515,
      "learning_rate": 0.00020128755364806866,
      "loss": 0.0631,
      "step": 1480
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.2247842252254486,
      "learning_rate": 0.00020092989985693845,
      "loss": 0.0568,
      "step": 1485
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.1993175595998764,
      "learning_rate": 0.0002005722460658083,
      "loss": 0.0599,
      "step": 1490
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.4343019127845764,
      "learning_rate": 0.0002002145922746781,
      "loss": 0.0594,
      "step": 1495
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.44012853503227234,
      "learning_rate": 0.0001998569384835479,
      "loss": 0.0692,
      "step": 1500
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.20809954404830933,
      "learning_rate": 0.00019949928469241773,
      "loss": 0.0609,
      "step": 1505
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.20445330440998077,
      "learning_rate": 0.00019914163090128755,
      "loss": 0.0646,
      "step": 1510
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.31080055236816406,
      "learning_rate": 0.00019878397711015734,
      "loss": 0.0803,
      "step": 1515
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.2855339050292969,
      "learning_rate": 0.00019842632331902718,
      "loss": 0.0579,
      "step": 1520
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.20988444983959198,
      "learning_rate": 0.000198068669527897,
      "loss": 0.0643,
      "step": 1525
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3518408238887787,
      "learning_rate": 0.00019771101573676678,
      "loss": 0.0627,
      "step": 1530
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3037448525428772,
      "learning_rate": 0.00019735336194563662,
      "loss": 0.0677,
      "step": 1535
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.29184490442276,
      "learning_rate": 0.0001969957081545064,
      "loss": 0.049,
      "step": 1540
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.25119301676750183,
      "learning_rate": 0.00019663805436337622,
      "loss": 0.0635,
      "step": 1545
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.33096569776535034,
      "learning_rate": 0.00019628040057224607,
      "loss": 0.0565,
      "step": 1550
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.24169181287288666,
      "learning_rate": 0.00019592274678111585,
      "loss": 0.0674,
      "step": 1555
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.277255654335022,
      "learning_rate": 0.00019556509298998567,
      "loss": 0.0582,
      "step": 1560
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.28092002868652344,
      "learning_rate": 0.0001952074391988555,
      "loss": 0.0559,
      "step": 1565
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.26973846554756165,
      "learning_rate": 0.0001948497854077253,
      "loss": 0.0662,
      "step": 1570
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.392054945230484,
      "learning_rate": 0.0001944921316165951,
      "loss": 0.0741,
      "step": 1575
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.354425311088562,
      "learning_rate": 0.00019413447782546493,
      "loss": 0.0648,
      "step": 1580
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4571303427219391,
      "learning_rate": 0.00019377682403433474,
      "loss": 0.0638,
      "step": 1585
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.2853561043739319,
      "learning_rate": 0.00019341917024320456,
      "loss": 0.0782,
      "step": 1590
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.3576328754425049,
      "learning_rate": 0.00019306151645207437,
      "loss": 0.0801,
      "step": 1595
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.21829260885715485,
      "learning_rate": 0.00019270386266094419,
      "loss": 0.0716,
      "step": 1600
    },
    {
      "epoch": 0.75,
      "eval_loss": 0.04060259833931923,
      "eval_runtime": 6.0998,
      "eval_samples_per_second": 16.394,
      "eval_steps_per_second": 2.131,
      "step": 1600
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.23888088762760162,
      "learning_rate": 0.000192346208869814,
      "loss": 0.0445,
      "step": 1605
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.40826112031936646,
      "learning_rate": 0.00019198855507868381,
      "loss": 0.0832,
      "step": 1610
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4001493752002716,
      "learning_rate": 0.00019163090128755363,
      "loss": 0.0608,
      "step": 1615
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.3273507058620453,
      "learning_rate": 0.00019127324749642344,
      "loss": 0.0713,
      "step": 1620
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.42000845074653625,
      "learning_rate": 0.00019091559370529326,
      "loss": 0.0831,
      "step": 1625
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3760060966014862,
      "learning_rate": 0.00019055793991416307,
      "loss": 0.0618,
      "step": 1630
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.33166638016700745,
      "learning_rate": 0.0001902002861230329,
      "loss": 0.0466,
      "step": 1635
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3191749155521393,
      "learning_rate": 0.0001898426323319027,
      "loss": 0.058,
      "step": 1640
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.30145150423049927,
      "learning_rate": 0.0001894849785407725,
      "loss": 0.0507,
      "step": 1645
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.18084831535816193,
      "learning_rate": 0.00018912732474964233,
      "loss": 0.0565,
      "step": 1650
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.27405235171318054,
      "learning_rate": 0.00018876967095851215,
      "loss": 0.053,
      "step": 1655
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.3304118514060974,
      "learning_rate": 0.00018841201716738193,
      "loss": 0.0708,
      "step": 1660
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.27193474769592285,
      "learning_rate": 0.00018805436337625178,
      "loss": 0.0659,
      "step": 1665
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2897149622440338,
      "learning_rate": 0.0001876967095851216,
      "loss": 0.0563,
      "step": 1670
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.4607256352901459,
      "learning_rate": 0.00018733905579399138,
      "loss": 0.0532,
      "step": 1675
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2763425409793854,
      "learning_rate": 0.00018698140200286122,
      "loss": 0.0673,
      "step": 1680
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3634325861930847,
      "learning_rate": 0.00018662374821173103,
      "loss": 0.0624,
      "step": 1685
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.202306866645813,
      "learning_rate": 0.00018626609442060082,
      "loss": 0.0594,
      "step": 1690
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.175253227353096,
      "learning_rate": 0.00018590844062947066,
      "loss": 0.0562,
      "step": 1695
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.4596022069454193,
      "learning_rate": 0.00018555078683834048,
      "loss": 0.0711,
      "step": 1700
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.2302711009979248,
      "learning_rate": 0.00018519313304721027,
      "loss": 0.0497,
      "step": 1705
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5523641705513,
      "learning_rate": 0.0001848354792560801,
      "loss": 0.0703,
      "step": 1710
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.30101436376571655,
      "learning_rate": 0.00018447782546494992,
      "loss": 0.0674,
      "step": 1715
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2503068149089813,
      "learning_rate": 0.0001841201716738197,
      "loss": 0.0624,
      "step": 1720
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.29245615005493164,
      "learning_rate": 0.00018376251788268955,
      "loss": 0.0523,
      "step": 1725
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.2758471667766571,
      "learning_rate": 0.00018340486409155937,
      "loss": 0.0532,
      "step": 1730
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.29602253437042236,
      "learning_rate": 0.00018304721030042915,
      "loss": 0.0456,
      "step": 1735
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.39058905839920044,
      "learning_rate": 0.000182689556509299,
      "loss": 0.0531,
      "step": 1740
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.2834306061267853,
      "learning_rate": 0.0001823319027181688,
      "loss": 0.05,
      "step": 1745
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.33127763867378235,
      "learning_rate": 0.0001819742489270386,
      "loss": 0.0635,
      "step": 1750
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.23101526498794556,
      "learning_rate": 0.00018161659513590844,
      "loss": 0.0608,
      "step": 1755
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.2807529866695404,
      "learning_rate": 0.00018125894134477826,
      "loss": 0.0539,
      "step": 1760
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.40092751383781433,
      "learning_rate": 0.00018090128755364804,
      "loss": 0.0629,
      "step": 1765
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.35573941469192505,
      "learning_rate": 0.00018054363376251786,
      "loss": 0.0695,
      "step": 1770
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.2637486457824707,
      "learning_rate": 0.0001801859799713877,
      "loss": 0.0498,
      "step": 1775
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.1965237408876419,
      "learning_rate": 0.0001798283261802575,
      "loss": 0.0572,
      "step": 1780
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.444889098405838,
      "learning_rate": 0.0001794706723891273,
      "loss": 0.0528,
      "step": 1785
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3149482011795044,
      "learning_rate": 0.00017911301859799714,
      "loss": 0.0426,
      "step": 1790
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.21802613139152527,
      "learning_rate": 0.00017875536480686693,
      "loss": 0.0469,
      "step": 1795
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5313242673873901,
      "learning_rate": 0.00017839771101573675,
      "loss": 0.0591,
      "step": 1800
    },
    {
      "epoch": 0.84,
      "eval_loss": 0.035898204892873764,
      "eval_runtime": 6.1003,
      "eval_samples_per_second": 16.393,
      "eval_steps_per_second": 2.131,
      "step": 1800
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.42313769459724426,
      "learning_rate": 0.0001780400572246066,
      "loss": 0.0744,
      "step": 1805
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.23150116205215454,
      "learning_rate": 0.00017768240343347637,
      "loss": 0.047,
      "step": 1810
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3553045690059662,
      "learning_rate": 0.0001773247496423462,
      "loss": 0.0609,
      "step": 1815
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.2542831003665924,
      "learning_rate": 0.00017696709585121603,
      "loss": 0.051,
      "step": 1820
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.45621612668037415,
      "learning_rate": 0.00017660944206008582,
      "loss": 0.0622,
      "step": 1825
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.2603256106376648,
      "learning_rate": 0.00017625178826895563,
      "loss": 0.0426,
      "step": 1830
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.2904890477657318,
      "learning_rate": 0.00017589413447782548,
      "loss": 0.0479,
      "step": 1835
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.313914030790329,
      "learning_rate": 0.00017553648068669526,
      "loss": 0.0484,
      "step": 1840
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.2787492871284485,
      "learning_rate": 0.00017517882689556508,
      "loss": 0.0496,
      "step": 1845
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.21683433651924133,
      "learning_rate": 0.00017482117310443486,
      "loss": 0.0489,
      "step": 1850
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.12799514830112457,
      "learning_rate": 0.0001744635193133047,
      "loss": 0.0476,
      "step": 1855
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.18261130154132843,
      "learning_rate": 0.00017410586552217452,
      "loss": 0.0564,
      "step": 1860
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.36002713441848755,
      "learning_rate": 0.0001737482117310443,
      "loss": 0.0553,
      "step": 1865
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.3979394733905792,
      "learning_rate": 0.00017339055793991415,
      "loss": 0.0603,
      "step": 1870
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.2462167590856552,
      "learning_rate": 0.00017303290414878397,
      "loss": 0.057,
      "step": 1875
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.23658210039138794,
      "learning_rate": 0.00017267525035765375,
      "loss": 0.0538,
      "step": 1880
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.18832965195178986,
      "learning_rate": 0.0001723175965665236,
      "loss": 0.0474,
      "step": 1885
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3326072096824646,
      "learning_rate": 0.0001719599427753934,
      "loss": 0.0644,
      "step": 1890
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.36808910965919495,
      "learning_rate": 0.0001716022889842632,
      "loss": 0.0525,
      "step": 1895
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4109671711921692,
      "learning_rate": 0.00017124463519313304,
      "loss": 0.061,
      "step": 1900
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.21520671248435974,
      "learning_rate": 0.00017088698140200285,
      "loss": 0.0541,
      "step": 1905
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3083690404891968,
      "learning_rate": 0.00017052932761087264,
      "loss": 0.0565,
      "step": 1910
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.278972864151001,
      "learning_rate": 0.00017017167381974248,
      "loss": 0.0489,
      "step": 1915
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3045056462287903,
      "learning_rate": 0.0001698140200286123,
      "loss": 0.0638,
      "step": 1920
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.4854000508785248,
      "learning_rate": 0.00016945636623748208,
      "loss": 0.0725,
      "step": 1925
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.23240798711776733,
      "learning_rate": 0.00016909871244635193,
      "loss": 0.0623,
      "step": 1930
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.23361395299434662,
      "learning_rate": 0.00016874105865522174,
      "loss": 0.0742,
      "step": 1935
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.2568933963775635,
      "learning_rate": 0.00016838340486409153,
      "loss": 0.0426,
      "step": 1940
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.1941661536693573,
      "learning_rate": 0.00016802575107296134,
      "loss": 0.0569,
      "step": 1945
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.19511570036411285,
      "learning_rate": 0.00016766809728183119,
      "loss": 0.0489,
      "step": 1950
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.32868361473083496,
      "learning_rate": 0.00016731044349070097,
      "loss": 0.0589,
      "step": 1955
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3772909641265869,
      "learning_rate": 0.0001669527896995708,
      "loss": 0.0654,
      "step": 1960
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3146301507949829,
      "learning_rate": 0.00016659513590844063,
      "loss": 0.0578,
      "step": 1965
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.24119244515895844,
      "learning_rate": 0.00016623748211731042,
      "loss": 0.0441,
      "step": 1970
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3831135034561157,
      "learning_rate": 0.00016587982832618023,
      "loss": 0.0631,
      "step": 1975
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.40105244517326355,
      "learning_rate": 0.00016552217453505007,
      "loss": 0.0463,
      "step": 1980
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.23239748179912567,
      "learning_rate": 0.00016516452074391986,
      "loss": 0.0464,
      "step": 1985
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.36247965693473816,
      "learning_rate": 0.00016480686695278968,
      "loss": 0.0454,
      "step": 1990
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3750598728656769,
      "learning_rate": 0.00016444921316165952,
      "loss": 0.0633,
      "step": 1995
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3554084599018097,
      "learning_rate": 0.0001640915593705293,
      "loss": 0.0658,
      "step": 2000
    },
    {
      "epoch": 0.93,
      "eval_loss": 0.03456512466073036,
      "eval_runtime": 6.1004,
      "eval_samples_per_second": 16.392,
      "eval_steps_per_second": 2.131,
      "step": 2000
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.43664246797561646,
      "learning_rate": 0.00016373390557939912,
      "loss": 0.0662,
      "step": 2005
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.32927247881889343,
      "learning_rate": 0.00016337625178826896,
      "loss": 0.049,
      "step": 2010
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.43043920397758484,
      "learning_rate": 0.00016301859799713875,
      "loss": 0.0542,
      "step": 2015
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.4249629080295563,
      "learning_rate": 0.00016266094420600856,
      "loss": 0.062,
      "step": 2020
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.3399917185306549,
      "learning_rate": 0.0001623032904148784,
      "loss": 0.0448,
      "step": 2025
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.33413147926330566,
      "learning_rate": 0.0001619456366237482,
      "loss": 0.056,
      "step": 2030
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.28131622076034546,
      "learning_rate": 0.000161587982832618,
      "loss": 0.0467,
      "step": 2035
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3413543105125427,
      "learning_rate": 0.00016123032904148785,
      "loss": 0.0531,
      "step": 2040
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.3875078856945038,
      "learning_rate": 0.00016087267525035764,
      "loss": 0.061,
      "step": 2045
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.19220729172229767,
      "learning_rate": 0.00016051502145922745,
      "loss": 0.0419,
      "step": 2050
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.29313215613365173,
      "learning_rate": 0.0001601573676680973,
      "loss": 0.0575,
      "step": 2055
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2588081955909729,
      "learning_rate": 0.00015979971387696708,
      "loss": 0.0505,
      "step": 2060
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2734256088733673,
      "learning_rate": 0.0001594420600858369,
      "loss": 0.0438,
      "step": 2065
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4111848771572113,
      "learning_rate": 0.0001590844062947067,
      "loss": 0.0582,
      "step": 2070
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.37230414152145386,
      "learning_rate": 0.00015872675250357653,
      "loss": 0.0524,
      "step": 2075
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.4276736378669739,
      "learning_rate": 0.00015836909871244634,
      "loss": 0.0441,
      "step": 2080
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.22323580086231232,
      "learning_rate": 0.00015801144492131615,
      "loss": 0.0565,
      "step": 2085
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.253491073846817,
      "learning_rate": 0.00015765379113018597,
      "loss": 0.0469,
      "step": 2090
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.21074804663658142,
      "learning_rate": 0.00015729613733905578,
      "loss": 0.0457,
      "step": 2095
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.3328034281730652,
      "learning_rate": 0.0001569384835479256,
      "loss": 0.0491,
      "step": 2100
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.25401267409324646,
      "learning_rate": 0.0001565808297567954,
      "loss": 0.0549,
      "step": 2105
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.2804581820964813,
      "learning_rate": 0.00015622317596566523,
      "loss": 0.0567,
      "step": 2110
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.3175954222679138,
      "learning_rate": 0.00015586552217453504,
      "loss": 0.0572,
      "step": 2115
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.20939399302005768,
      "learning_rate": 0.00015550786838340483,
      "loss": 0.0505,
      "step": 2120
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.17654243111610413,
      "learning_rate": 0.00015515021459227467,
      "loss": 0.0465,
      "step": 2125
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.29647624492645264,
      "learning_rate": 0.0001547925608011445,
      "loss": 0.0584,
      "step": 2130
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.29461827874183655,
      "learning_rate": 0.00015443490701001427,
      "loss": 0.0495,
      "step": 2135
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.294330358505249,
      "learning_rate": 0.00015407725321888412,
      "loss": 0.0494,
      "step": 2140
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.36776748299598694,
      "learning_rate": 0.00015371959942775393,
      "loss": 0.0692,
      "step": 2145
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3714010417461395,
      "learning_rate": 0.00015336194563662372,
      "loss": 0.0582,
      "step": 2150
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.2743304669857025,
      "learning_rate": 0.00015300429184549356,
      "loss": 0.059,
      "step": 2155
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.3463503420352936,
      "learning_rate": 0.00015264663805436337,
      "loss": 0.0481,
      "step": 2160
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.3502030372619629,
      "learning_rate": 0.00015228898426323316,
      "loss": 0.051,
      "step": 2165
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.3211176097393036,
      "learning_rate": 0.000151931330472103,
      "loss": 0.0476,
      "step": 2170
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.2604806125164032,
      "learning_rate": 0.0001515736766809728,
      "loss": 0.0384,
      "step": 2175
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.3109077215194702,
      "learning_rate": 0.0001512160228898426,
      "loss": 0.0429,
      "step": 2180
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.41163647174835205,
      "learning_rate": 0.00015085836909871245,
      "loss": 0.0494,
      "step": 2185
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.3921826481819153,
      "learning_rate": 0.00015050071530758224,
      "loss": 0.0468,
      "step": 2190
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.324468731880188,
      "learning_rate": 0.00015014306151645205,
      "loss": 0.0518,
      "step": 2195
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.22196276485919952,
      "learning_rate": 0.0001497854077253219,
      "loss": 0.0442,
      "step": 2200
    },
    {
      "epoch": 1.02,
      "eval_loss": 0.033737119287252426,
      "eval_runtime": 6.1001,
      "eval_samples_per_second": 16.393,
      "eval_steps_per_second": 2.131,
      "step": 2200
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.34931445121765137,
      "learning_rate": 0.00014942775393419168,
      "loss": 0.0435,
      "step": 2205
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.3214437663555145,
      "learning_rate": 0.0001490701001430615,
      "loss": 0.0492,
      "step": 2210
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.2557828426361084,
      "learning_rate": 0.00014871244635193134,
      "loss": 0.044,
      "step": 2215
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.22940608859062195,
      "learning_rate": 0.00014835479256080112,
      "loss": 0.0512,
      "step": 2220
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.42044660449028015,
      "learning_rate": 0.00014799713876967094,
      "loss": 0.0524,
      "step": 2225
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.2786727249622345,
      "learning_rate": 0.00014763948497854078,
      "loss": 0.0491,
      "step": 2230
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.49843478202819824,
      "learning_rate": 0.00014728183118741057,
      "loss": 0.0522,
      "step": 2235
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.2601841390132904,
      "learning_rate": 0.00014692417739628038,
      "loss": 0.0377,
      "step": 2240
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.2383396178483963,
      "learning_rate": 0.0001465665236051502,
      "loss": 0.0522,
      "step": 2245
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.2497292309999466,
      "learning_rate": 0.00014620886981402,
      "loss": 0.0413,
      "step": 2250
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.3282560408115387,
      "learning_rate": 0.00014585121602288983,
      "loss": 0.0488,
      "step": 2255
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.18519453704357147,
      "learning_rate": 0.00014549356223175964,
      "loss": 0.0465,
      "step": 2260
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.26439109444618225,
      "learning_rate": 0.00014513590844062946,
      "loss": 0.0442,
      "step": 2265
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.22906944155693054,
      "learning_rate": 0.00014477825464949927,
      "loss": 0.0523,
      "step": 2270
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.24123430252075195,
      "learning_rate": 0.00014442060085836908,
      "loss": 0.0418,
      "step": 2275
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.47261789441108704,
      "learning_rate": 0.0001440629470672389,
      "loss": 0.0503,
      "step": 2280
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.325481653213501,
      "learning_rate": 0.00014370529327610871,
      "loss": 0.0478,
      "step": 2285
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.41141921281814575,
      "learning_rate": 0.00014334763948497853,
      "loss": 0.0594,
      "step": 2290
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.33139777183532715,
      "learning_rate": 0.00014298998569384834,
      "loss": 0.0554,
      "step": 2295
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.25744718313217163,
      "learning_rate": 0.00014263233190271816,
      "loss": 0.0497,
      "step": 2300
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.2827523648738861,
      "learning_rate": 0.00014227467811158797,
      "loss": 0.0459,
      "step": 2305
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.3589775562286377,
      "learning_rate": 0.0001419170243204578,
      "loss": 0.0485,
      "step": 2310
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.20821736752986908,
      "learning_rate": 0.0001415593705293276,
      "loss": 0.0473,
      "step": 2315
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.17865249514579773,
      "learning_rate": 0.00014120171673819742,
      "loss": 0.0479,
      "step": 2320
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.4232371151447296,
      "learning_rate": 0.00014084406294706723,
      "loss": 0.0471,
      "step": 2325
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.20833124220371246,
      "learning_rate": 0.00014048640915593705,
      "loss": 0.0497,
      "step": 2330
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.2807990312576294,
      "learning_rate": 0.00014012875536480686,
      "loss": 0.0469,
      "step": 2335
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.273583322763443,
      "learning_rate": 0.00013977110157367668,
      "loss": 0.0472,
      "step": 2340
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.21898022294044495,
      "learning_rate": 0.0001394134477825465,
      "loss": 0.0482,
      "step": 2345
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.37678995728492737,
      "learning_rate": 0.0001390557939914163,
      "loss": 0.0471,
      "step": 2350
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.2818632423877716,
      "learning_rate": 0.00013869814020028612,
      "loss": 0.0394,
      "step": 2355
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.3352774977684021,
      "learning_rate": 0.00013834048640915593,
      "loss": 0.058,
      "step": 2360
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.17938017845153809,
      "learning_rate": 0.00013798283261802572,
      "loss": 0.0408,
      "step": 2365
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.14600028097629547,
      "learning_rate": 0.00013762517882689556,
      "loss": 0.0513,
      "step": 2370
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.464000940322876,
      "learning_rate": 0.00013726752503576538,
      "loss": 0.0422,
      "step": 2375
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.3179532289505005,
      "learning_rate": 0.00013690987124463517,
      "loss": 0.0471,
      "step": 2380
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.26255661249160767,
      "learning_rate": 0.000136552217453505,
      "loss": 0.0494,
      "step": 2385
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.4615829288959503,
      "learning_rate": 0.00013619456366237482,
      "loss": 0.0456,
      "step": 2390
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.23059089481830597,
      "learning_rate": 0.0001358369098712446,
      "loss": 0.0483,
      "step": 2395
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.25549423694610596,
      "learning_rate": 0.00013547925608011445,
      "loss": 0.0492,
      "step": 2400
    },
    {
      "epoch": 1.12,
      "eval_loss": 0.03157433867454529,
      "eval_runtime": 6.1002,
      "eval_samples_per_second": 16.393,
      "eval_steps_per_second": 2.131,
      "step": 2400
    }
  ],
  "logging_steps": 5,
  "max_steps": 4294,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "total_flos": 1.7714148281753272e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
